---
title: "MSF_Groupwork-NBA_shotlog"
author: "Team_9"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Report produced by: Justin Leiendecker, Alexander Romanenko, Artmeis Tomadaki-Balomenou, Zijun Wei, Reza Brianca Widodo  
Date submitted: 16/10/2016

#Report structure 

##Introduction

The purpose of this report is to analyse the chosen dataset and to produce meaningful results using statistical and mathematical analysis. These analyses have been conducted using RStudio software. This report will focused on analysis of a number of areas, demonstrate how the analysis has been conducted, discusses theory used, demonstrate and evaluate produced results. In addition, where relevant, this report will highlight potential areas of future research. 

The chosen dataset for this report is a summary of shots made during NBA season 2015-2016. The following areas of research have been selected:

**1. Team related**
  a. Home Advantage analysis
  b. Effect of rest on teams' performance
  
**2. Player related**
  a. Effects on Accuracy 
  b. Shot Clock Pressure
  c. Fatigue Effect (Quarter Accuracy Rate)  
  d. Game result impact by field goal attempts
  e. Defender Proximity Analysis
  f. Shooting Distance vs Shot Accuracy 
  g. Hot Hand Theory 


###Dataset Description:  
  
Data  contains full set of shot attempts by each team/player during the NBA 2014-2015 season for regular matches throughout the year. The data comprise of 128,609 rows and 22 columns with. The column titles (variables) are as follows:   
    1.  Match ID  
    2.  Match date and names of contestants  
    3.  Location: home and away  
    4.  Match result  
    5.  Final score difference  
    6.  shot number  
    7.  Shot result: success or miss 
    8.  Type of shot attempt (2 points or 3 points)  
    9.  Quarter number (1 to 4, or higher for overtime)  
    10. Game clock for each quarter when the shot has been made 
    11. Shot clock (time left for a shot)  
    12. Name and ID of a player who took the shot  
    13. Shot distance from basket  
    14. Name and ID of the nearest defender  
    15. Distance from the nearest defender  
  
 The data has been acquired from Kaggle website **(https://www.kaggle.com/dansbecker/nba-shot-logs)** on 30 September 2016.  

###Dataset Strengths  
    
    The dataset comprises of comprehensive observational data which enables efficient analysis without extensive 'clean up' of the data. The dataset only have small percentage of missing value (0.19%), therefore there is no need to remove or assign numerous data points to default values. The fact that initial dataset meant that only a small number of additional columns had to be added (see data clean-up part of the code for details. 

###Dataset Limitations  
  There are several limitations of the dataset:  
    1. The dataset consists only 1 year NBA season stats (2014-2015)  
    2. The dataset comprise only the data for regular season matches  
    3. The playoff and other matches during the year are not included
    4. The dataset does not include information on free throw shots
    5. The dataset does not include final scores of the games

##Analysis

### Installing libraries

install.packages('reshape')
install.packages('gridExtra')

### Calling libraries
```{r}
library(reshape)
library(ggplot2)
library(gridExtra)
library(plyr)

```


###Data clean-up 

```{r}
df <- read.csv("shot_logs.csv")  #assigning the dataframe to 'df' variables
attach(df) #telling R that this is the dataframe we'll be working with (eliminating the need to use df$ for variables)

df1 <- read.csv("shot_logs1010.csv")

# replacing W/L in column "W" with 1/0 (1 for win, 0 for loss)
df[, "W"] <- as.character(df[, "W"])

for (i in 1:nrow(df)) {
  if (df[i, "W"] == "W") df[i, "W"] <- 1
  if (df[i, "W"] == "L") df[i, "W"] <- 0
}

df[, "W"] <- as.numeric(df[, "W"])
```

```{r}
#adding columns for names of 'home' and 'away' teams. In addition, WINNER column tells which team won
df[, "MATCHUP"] <- as.character(df[, "MATCHUP"])
df[, "W"] <- as.character(df[, "W"])

for (i in 1:nrow(df)) {
  if (LOCATION[i] == "H") {
    df$HOME_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[5]
    df$AWAY_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[7]
    if (W[i] == "W") df$WINNER[i] <- "HOME" 
    if (W[i] == "L") df$WINNER[i] <- "AWAY"
  }
  if (LOCATION[i] == "A") {
    df$HOME_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[7] 
    df$AWAY_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[5]
    if (W[i] == "L") df$WINNER[i] <- "HOME"  
    if (W[i] == "W") df$WINNER[i] <- "AWAY"
  }
}

#adding a column 'DATE'
df1[, "MATCHUP"] <- as.character(df1[, "MATCHUP"])
for (i in 1:nrow(df1)) df1$DATE[i] <- as.character(as.Date(unlist(strsplit(df1$MATCHUP[i], " -"))[1], format = "%B %d, %Y"))

#creating a column for 'TEAM'. This column relates to the team whose player made a shot described by the dataframe
for (i in 1:nrow(df1)) df1$TEAM[i] <-unlist(strsplit(df1$MATCHUP[i], " "))[5]

#preparing dataframe for rest days calculation
df1$BLANK2<-""
restdays2 <- cast(df1, TEAM + DATE + LOCATION + W + FINAL_MARGIN ~ FGM)
restdays2$DATE<- as.Date(restdays2$DATE)

```

## Home Advantage analysis
###Introduction

This area of analysis focuses on investigation of whether playing at 'home' gives the team advantage comparing to when playing 'away'. Esssentially, this analysis focuses on effect of the game lovation (home/away) on winning ratio.

The NULL Hypothesis: Teams playing at home is more likely to win then when playing away.

###Methods
Steps to test the hypothesis are as follows:  
    1. Calculate a total number of games, which has been won by a home or away team
    2. Compare the total win numbers to identify whether home advantage is evident using means of the variables
    3. Extend the analysis to review of the home/away wins on a team level 
    4. Plot the team level data 
    5. Discuss the findings of the analysis


```{r}
#preparing a dataframe for home advantage analysis
aa <- cast(df1, GAME_ID1 + HOME_TEAM + AWAY_TEAM + WINNER ~ W)

#table showing a number of games won by home and away teams in the whole season
table(aa$WINNER)

#home wins:
hh <- sum(aa$WINNER == "HOME")
#Away wins:
aw <- sum(aa$WINNER == "AWAY")

#percentage of home team winning: 
round(hh / (hh + aw), 4)
round(aw / (hh + aw), 4)

```

```{r}
#preparing a dataframe for analysis of games when a team played at home 
aa1 <- cast(aa, HOME_TEAM ~ WINNER); names(aa1)[1] <- "TEAM"
aa1$WIN_PCT_HOME <- round(aa1$HOME / (aa1$HOME + aa1$AWAY), 2)

#preparing a dataframe for analysis of games when a team played at away 
aa2 <- cast(aa, AWAY_TEAM ~ WINNER); names(aa2)[1] <- "TEAM"
aa2$WIN_PCT_AWAY <- round(aa2$AWAY / (aa2$HOME + aa2$AWAY), 2)

#merging two dataframes together to enable the effective analysis of win ratios for teams playing at home and away.
aa3 <- merge (aa1, aa2, by ="TEAM")

#ordering the dataframe by win percentage at home.
aa3 <- aa3[order(aa3$WIN_PCT_HOME, decreasing = TRUE),]

#ordering factors of the dataframe by win percentage at home.
aa3$TEAM <- factor(aa3$TEAM, levels = aa3$TEAM[order(-aa3$WIN_PCT_HOME)])

#creating a column which shows a difference between home and away winning percentage rate
aa3$WIN_PCT_DIFF<- aa3$WIN_PCT_HOME - aa3$WIN_PCT_AWAY

```

```{r}
#plot showing home and away win ratio per team
ggplot(aa3, aes(x = TEAM)) + geom_point(aes(y = WIN_PCT_HOME, col = "HOME")) + geom_point(aes(y = WIN_PCT_AWAY, col = "AWAY")) 
```


###Findings
Table 1: Proportion of total games split by Location win factor

X     | HOME WIN | AWAY WIN
----- | -------- | ---
Game  | 506      | 398
Perc  | 55.97%   | 44.03%

Tables 2 & 3: Winning ratio of teams playing at home vs games playing away 

TEAM        | GSW | ATL | POR | MEM | SAS | CLE | HOU | LAC | OKC | DAL | NOP | WAS | TOR | CHI | MIL  
------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----
Win % HOME  |   93| 88  | 81  | 77  | 75  | 72  | 72  | 72  | 71  | 68  | 68  | 68  | 66  | 59  | 59 
Win % AWAY  |   69| 71  | 54  | 67  | 50  | 53  | 61  | 57  | 42  | 61  | 40  | 43  | 59  | 66  | 45 
Win % Diff  |   24| 17  | 27  | 10  | 25  | 19  | 11  | 15  | 29  | 7   | 28  | 25  | 7   | -7  | 14


TEAM        | PHX | IND | BOS | CHA | UTA | DEN | BKN | SAC | MIA | DET | LAL | ORL | PHI | NYK |MI 
------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----
Win % HOME  | 57  | 52  | 48  | 47  | 45  | 42  | 41  | 41  | 39  | 38  | 31  | 30  | 28  | 27  | 26 
Win % AWAY  | 47  | 35  | 32  | 41  | 35  | 30  | 44  | 30  | 48  | 39  | 23  | 31  | 16  | 14  | 18 
Win % Diff  | 10  | 17  | 16  | 6   | 10  | 12  |-3   | 11  |-9   |-1   |    8|   -1|   12|   13| 8



The plot shows that out of 30 teams:
  25 teams have won more games at home than away
  3 teams have won more games away than at home
  2 teams home and away win ratios are almost equal (difference of less than or equal to 1%)


###Variance test Analysis
```{r}

```

###regression analysis

```{r}
margreg<- lm(FINAL_MARGIN ~ LOCATION, restdays2)
summary(margreg)
```

Table 4: Regression Analysis

  X         |Estimate |Std. Error| t value| Pr(>t)    
------------|---------|--|--|------------------------
(Intercept) |-2.12919 |   0.51589 | -4.127 |3.84e-05 ***
LOCATIONH   |4.28556  |  0.63881  | 6.709 |2.63e-11 ***
rest        |-0.01129 |   0.25992 | -0.043 |   0.965 
  

Adjusted R-squared = 0.02392

###Discussion

The analysis shown that there is a clear evidence that a team playing at home is more likely to win with an average win probability of 55.97%. The same conclusion is evident from the analysis conducted on a team level where 25 teams are winning more games at home than away. The result shown that the NULL hypothesis should be rejected as a team playing at home is more likely to win then an away team. Regression analysis shown that playing at home gives teams on average additional 4.29 margin points. 

The result of this research also confirms recent trend of decline in home advantage over the years: probability of a home team winning has reduced from around 65% in 1975-1992 to average of 60.3% in 1993-2011 and to around 58.5% for 2011-15. Home win ratio was 57.4% win in 2014-2015 season. The analysis demonstrated that the home win ratio went down even further to 56.0% in 2015-2016 season. Based on the literature review this trend could be potentially explained by the following factors (http://www.economist.com/blogs/gametheory/2015/06/home-advantage-basketball):

  1. Improvement of travel conditions. This means that when playing away, teams are now more likely to stay at better hotels and fly charterd planes more often than in the past. These changes result in teams being less tired as a consequence of travel and being better physically prepared for the games.
  
  2. Change in style of play in NBA. The game now is more open with less physical contact, which reduces number of fouls and potential impact of 'notorious home-team bias' by referees.



##Effect of rest on teams' performance

###Introduction

This area of analysis focuses on investigation of whether a number of rest days between games affect performance and more importantly winning ratio of a team. 

The Null Hypothesis is: By having longer rest a team is likely to have a higher winning ratio.

###Methods
The steps to calculate this measurement are as follows:  
    1. Calculating number of rest days between games for all teams
    2. Calculating ratios for effects of rest days on win/loss
    3. Calculating ratios for effects of rest days on win/loss form home/awayCalculating ratios for effects of rest days on win/loss
    4. Discuss the findings of the data
    

```{r}


#calulating number of rest days between teams
for (i in 2: nrow (restdays2)) {
  if (restdays2$TEAM[i]==restdays2$TEAM[i-1])
    restdays2$rest[i]<- as.numeric(restdays2$DATE[i] - restdays2$DATE[i-1]-1)
  else 
    (restdays2$rest[i]<- "NA")  
}
restdays2$BLANK<-""

restdays2$rest <- as.numeric (restdays2$rest)

#regression analysis
margreg<- lm(FINAL_MARGIN ~ LOCATION + rest, restdays2)
summary(margreg)


#creating dataframe for total rest days
restdays4<- cast (restdays2, rest ~  W)
colnames(restdays4)<- c( "rest", "L","W") 

#creating a column for total restdays for a team when lost and won to enable calculation of ratios
restdays4$total<-restdays4$L + restdays4$W
restdays4$dist <-   round (restdays4$total * 100 /sum (restdays4$total) ,2)

#plotting distribution of rest days to establish which of the rows should be analysed
restdays4[,c(1,4,5)]
#The distribution of rest days show that 92% of games are covered by 0,1 or 2 days of rest and therefore further analysis will only focus on these 3 sections

restdays4$ L.pct <-   round(restdays4$L*100/(restdays4$L+restdays4$W),2) 
restdays4$ W.pct <-   round(restdays4$W*100/(restdays4$L+restdays4$W),2)

print (restdays4[1:3,c(1,3,7)])

#creating a new dataframe for summary of home/away win losses based on number of rest days.
restdays3<- cast (restdays2, rest ~ LOCATION + W) ; 

#renaming the columns
colnames(restdays3)<- c( "rest", "AL","AW","HL", "HW") 

#caluclating ratios
restdays3$ AL.pct <-   round(restdays3$AL*100/(restdays3$AL+restdays3$AW),2) 
restdays3$ AW.pct <-   round(restdays3$AW*100/(restdays3$AL+restdays3$AW),2)
restdays3$ HL.pct <-   round(restdays3$HL*100/(restdays3$HL+restdays3$HW),2)
restdays3$ HW.pct <-   round(restdays3$HW*100/(restdays3$HL+restdays3$HW),2)

print (restdays3[1:3,c(1,7,9)])


#Testing of rest data

#t.test(x=restdays2$W[restdays2$rest==0], y= restdays2$W[restdays2$rest==1])
#chisq.test(x=restdays2$W[restdays2$rest==0], y= restdays2$W[restdays2$rest==1])


#restdays2$W[restdays2$rest==0,]

```

###Findings

Table 5: Distribution of number of games per rest days

 Rest Days| Games | Distribution
----------|-------|---
    0  | 427 | 23.62
    1  | 990 | 54.76
    2  | 254 | 14.05
    3  |  59 |  3.26
    4  |  13 |  0.72
    5  |   3 | 0.17
    7  |   6 | 0.33
    8  |  20 | 1.11
    9  |   3 | 0.17
    10 |   3 | 0.17
   1st game of season  |  30|  1.66

The distribution of rest days shows that 92% of games are covered by 0,1 or 2 days of rest and therefore further analysis will only focus on these 3 sections.

Table 6: Win Rate split by number of rest days between games

  rest days| number of wins| win percentage
-|-|-
    0| 201| 47.07
    1| 496| 50.10
    2| 137| 53.94


Table 7: Win Rate split by number of rest days between games and location

  rest days| home wins percentage | away wins percentage|
-|-|-
    0|   53.54 |44.33 
    1 | 54.68 |  44.24
    2  | 59.57 | 46.90

###Discussion

The analysis demonstrated that overall winning ratio improves with increase in  rest days: back-to-back games had 47.07% winning ratio, 1 day rest increased winning ratio to 50.10% and with 2 days rest the winning ration has increased even further to 53.94%.

By extending the analysis to the team level, the results have demonstrated similar tendency for home  games where winning ratio has increased from 53.54% to 54.68% and 59.57% respectively with 0, 1 and 2 days of rest. Somewhat interestingly the analysis of effect of rest days on winning ratio of away games demonstrated that there is hardly any difference between 0 and 1 days of rest (44.33% and 44.24%). However with 2 days of rest teams' average winning ratio have increased to 46.90% (2.66% increase). This perhaps could be explained by the fact that teams were able to minimise effect of travelling when having a bigger window between games.

Based on the above, the analysis shown that the null hypothesis should be rejected as there is a clear evidence that the higher rest days correspond to higher winning ratio

###Further research

To better understand effects of rest and home/away advantage it would be interesting in future research papers to take into account distances the teams have to travel between the games. For example if a team is travelling from one coast to another- it is likely to affect them more comparing to a team from New York 'travelling' to play an away gamein New Jersey.

##Effects on accuracy (Justin)


The potential effects of fatigue and stress on the accuracy of shots are investigated in this part of the analysis.

Fatigue in basketball is a broadly analysed topic in physiological research. Latest literature suggests that elite basketball players cope well with the effects of fatigue so it does not affect their shooting kinematics. This results in no difference for their shot accuracy even if the players are fatigued (Erčul, Frane & Supej, 2006; Uygur et al., 2010). This research paper analyses whether these previous findings can be confirmed for the NBA season 2015-2016.  

Regarding the effect of psychological stress on shot accuracy, previous research is not as decisive as for the effects of fatigue. While Arhart(1973) concluded that stressful events like small or big margins for the game score have an effect on players free-throw accuracy, latest research introducing more controlled conditions states that there is no effect of stress on players shot accuracy (Mascret et al., 2016). The indecisiveness of previous literature led to a deeper analysis in this research paper.


Hypotheses for this area of analysis are:

Fatigue: The Null hypothesis states that there is no significant difference (p < .05) for the shot accuracy in later periods of the game.

Stress: The Null hypothesis states that there is no significant difference (p < .05) for the shot accuracy in more stressful events.


###METHOD

In this analysis fatigue was measured as the period of the game, as it can be assumed that the later in the game the higher the fatigue of the players.

The steps to test the first hypothesis were as follows:
  1. The overall accuracy for each period was calculated, based on the number of shots made (FGM = 1) and the number of shots taken for the specific period (FGM = 1 & FGM = 0)
  2. This results in a percentage value of shots made for each of the periods
  3. A variable called "Overtime" was introduced to distinguish between periods in the regular game time and overtime
  4. The average accuracy for regular time and overtime was calculated
  5. A T-test was used to examine whether or not these values were significant different at a level of significance of 5%.
  
  
Psychological stress was measured through the remaining time on the shot clock for each shot taken. It was assumed that a player would experience more stress the lower the shot clock goes.

The steps to test the second hypothesis were as follows:
  1. As the shot clock variable contained 5567 missing values, those were excluded from the analysis
  2. To simplify the shot clock variable, decimals were removed from the data so every shot taken was assigned to 0 to 24 seconds left on the shot clock
  3. The overall accuracy for each second was calculated using the FGM variable


```{r}

### FATIGUe

# accuracy per period

df.acc <- data.frame()
  
for (i in (1:7)){
  df.acc[i, "accuracy"] <- sum(df$PERIOD == i & df$FGM == 1) / sum(df$PERIOD == i)
  df.acc[i, "period"] <- i
  if (df.acc$period[i] <= 4) df.acc[i, "overtime"] <- 0
  if (df.acc$period[i] >= 5) df.acc[i, "overtime"] <- 1
}

regular <- sum(df.acc$accuracy[df.acc$period <= 4])/4
overtime <- sum(df.acc$accuracy[df.acc$period >=5])/3


t.test(df$FGM[df$PERIOD == 1], df$FGM[df$PERIOD == 2])
t.test(df$FGM[df$PERIOD == 2], df$FGM[df$PERIOD == 3])
t.test(df$FGM[df$PERIOD == 3], df$FGM[df$PERIOD == 4])
t.test(df$FGM[df$PERIOD == 1], df$FGM[df$PERIOD == 3])
t.test(df$FGM[df$PERIOD == 2], df$FGM[df$PERIOD == 4])
t.test(df$FGM[df$PERIOD == c(1:4)], df$FGM[df$PERIOD == c(5:7)])


### STRESS
# accuracy for Shot Clock

# dealing with missing values
df1[is.na(df1)] <- 99

acc <- data.frame(seconds.left = c(0:24))

#accuracy for every second
for (i in (0:24)){
  acc[i, "accuracy"] <- (sum(df1$SHOT_CLOCK >= i & df1$SHOT_CLOCK < i + 1 & df1$SHOT_CLOCK != 99 & df1$FGM == 1) / sum(df1$SHOT_CLOCK >= i & df1$SHOT_CLOCK < i + 1 & df1$SHOT_CLOCK != 99))
}

ggplot(acc, aes(x = seconds.left, y = accuracy)) + geom_point() + geom_smooth()



#accuracy for players per second

##simplifying shot clock to seconds left
  
df.acc.players <- cast(df1, player_id + player_name + SHOT_CLOCK ~ FGM)

for (i in (1:nrow(df.acc.players))){
  for (j in (0:24)){
    if (df.acc.players$SHOT_CLOCK[i] >= j & df.acc.players$SHOT_CLOCK[i] < j + 1) df.acc.players[i, "seconds.left"] <- j
    if (df.acc.players$SHOT_CLOCK[i] == 99) df.acc.players[i, "seconds.left"] <- 99
  }
}


ap<- df.acc.players
head(ap)

ap$SHOT_CLOCK <- NULL

colnames(ap)<- c( "player_id", "player_name","X0", "X1","seconds.left") 


ap2 <- ddply(ap, c("player_id", "player_name","seconds.left"), summarise,
X0= sum(X0),
X1= sum(X1))

ap2$acc<- ap2$X1/(ap2$X0+ap2$X1)

ap2[ap2 == 99] <- NA

ap3 <- data.frame(row.names = c(0:24))
ap3$seconds.left <- c(0:24)

for (i in ap3$seconds.left){
  ap3$acc.top[ap3$seconds.left == i] <- sum(ap2$acc[ap2$seconds.left == i & ap2$player_name == "james harden"][!is.na(ap2$acc[ap2$seconds.left == i & ap2$player_name == "james harden"])], ap2$acc[ap2$seconds.left == i & ap2$player_name == "lebron james"][!is.na(ap2$acc[ap2$seconds.left == i & ap2$player_name == "lebron james"])], ap2$acc[ap2$seconds.left == i & ap2$player_name == "russell westbrook"][!is.na(ap2$acc[ap2$seconds.left == i & ap2$player_name == "russell westbrook"])])/3}



ggplot(NULL) + geom_smooth(data = ap3, aes(x = seconds.left, y = acc.top, color = "Top Players")) + geom_smooth(data = acc, aes(x = seconds.left, y = accuracy, color = "Average"))


t.test(acc$accuracy, ap3$acc.top)

```

###Results

The accuracies for each period are detailed in the table below. 

Period  | Accuracy
------- | ---------
1       | 46%
2       | 45%
3       | 46%
4       | 44%
5       | 39%
6       | 43%
7       | 37%
regular | 45%
overtime | 40%



The T-tests for period 1 and period 2 was significant, t(65301) = 2.42, p = .015, as well as the T-test for period 3 and 4, t(60757) = 4.24, p < .01. Further the T-test for period 2 and 3 was not significant, t(63843) = -1.53, p = .126, as well as the T-test for period 1 and 3, t(65989) = 0.87, p = .38. 
The T-test for regular time and overtime was highly significant, t(383) = 2.77, p < .01.


The changes in the overall accuracy per second are shown in the graph below.

```{r}
graph.acc <- ggplot(acc, aes(x = seconds.left, y = accuracy)) + geom_point() + geom_smooth()

graph.acc + labs(title = "Overall Accuracy per second left on shot clock") + xlab("Seconds left on shot clock") + ylab("Overall Accuracy")
```

### Discussion

The results of the T-tests show a significant difference for the overall accuracy between period 1 and period 2, between period 3 and period 4 and between regular game time and overtime. As the table shows the changes in accuracy are really small (from 46% to 44% over the regular game time) and often located on digit-level, so eventhough the changes are significant they are negligible. After all, there is not enought evidence to reject the Null hypothesis, statingthat there is no difference in the accuracy for later periods, in regular game time but it can be rejected for overtime. It can be concluded that accuracy does not suffer for later game periods as long as the game ends in regular time. For games that reach overtime a highly significant drop in the accuracy of over 5% (45% to below 40%) is observale. 
This means that elite basketball players cope really well with any occurance of fatigue regarding their shot accuracy on a regular basis. As soon as the game reaches an intensity which is beyond the regular level effects of fatigue can be found leading to lower shot accuracy. 


The effects of psychological stress are highly visible as shown in the graph above. While the accuracy in the first 10 seconds of the shot clock is exceeding the overall accuracy in the regular game time (60-45% vs 45% in regular game time), it declines quite fast in the last 5 seconds of the shot clock (from 42% to 32%), leading to the rejection of the Null hypothesis, that there are no differences in the accuracy for more stressful events. These results imply that as the shot clock runs out, so as the psychological pressure on the shooter increases, their shot performance suffers. ??????


An ad hoc data analysis was undertaken to investigate whether this pattern of stress-inducted accuracy declination can be found as well for "superstar" players. The players were Lebron James, James Harden and Russel Westbrook, chosen because they were the top 3 shooters in the season. Their combined average accuracy per second can be seen in the graphic below. 

```{r}

graph2 <- ggplot(NULL) + geom_smooth(data = ap3, aes(x = seconds.left, y = acc.top, color = "Top Players")) + geom_smooth(data = acc, aes(x = seconds.left, y = accuracy, color = "Average"))
graph2 + labs(title = "Comparison - Accuracy per second on shot clock left for Top Players vs Overall Average") + xlab("Seconds left on shot clock") + ylab("Accuracy")

```

The graph shows many similarities for top players to the average graph. The most visual differences are the slightly lower accuracy around the 15 seconds mark for the top players and the much lower decrease below 5 seconds left. Explanations for these differences could be that around the 15 second mark top players feel more obligated to shoot than the average player, even when they are not in the optimal position to do so - leading to lower accuracies. Further it seems like Top players dont get affected by last seconds stress as much as average players. They keep up a quite high accuracy even for the last second of the shot clock (40%).

### Future research

Future research could focus on this difference between Top players and average players. While this analysis revealed a difference for shot clock pressure it would be interesting to look at more events that induce stress like the margin of the game or the placement in the standings of the own and the enemy team.

## Shooting Percentage Analysis (James)

```{r}
# Replace "made" and "missed" with 1 and 0 respectively

df[, "SHOT_RESULT"] <- as.character(df[, "SHOT_RESULT"])
 
for (i in 1:nrow(df)) {
  if (df[i, "SHOT_RESULT"] == "made") df[i, "SHOT_RESULT"] <- 1
  if (df[i, "SHOT_RESULT"] == "missed") df[i, "SHOT_RESULT"] <- 0
}

df[, "SHOT_RESULT"] <- as.numeric(df[, "SHOT_RESULT"])

```

### Find shooting percentage of each match
### Find field goal percentage (FG percentage) for each match


```{r}
# Reshape the dataframe

shot.stats <- cast(data = df1, GAME_ID1 + HOME_TEAM + AWAY_TEAM + LOCATION  + W + player_name + FINAL_MARGIN ~ FGM)

# Field Goal Attempts

shot.stats[, "FGA"] <- NA
for(i in 1:nrow(shot.stats)){
  shot.stats[i, "FGA"] <- shot.stats[i, "1"] + shot.stats[i, "0"]
}

# Find Feild Goal Percentage of each indivudual player in that match

shot.stats[, "FG.percentage"] <- NA 
for (i in 1:nrow(shot.stats)){
  shot.stats[i, "FG.percentage"] <- round(((shot.stats[i, "1"]/shot.stats[i, "FGA"]) * 100), digits = 2)
}
```

<<<<<<< HEAD
### Impact of Super Star Players
### Impact of Top Scorers


```{r}
# Pick out 15 of the best players in that regular season and create a new subset. Analyse how shooting percentage of these players can influence the result of a match.

top.scorers.list <- c("mnta ellis", "lebron james", "james harden", "russell westbrook", "stephen curry", "anthony davis", "blake griffin", "lamarcus aldridge", "dwayne wade", "carmelo anthony", "eric bledsoe", "demarcus cousins", "kawhi leonard", "gordon hayward", "john wall") # 15 players picked out from all players
top.scorers <- shot.stats[shot.stats$player_name %in% top.scorers.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")] # create a subset for these players
top.scorers2 <- shot.stats[shot.stats$player_name %in% top.scorers.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")] # create a subset for these players

# Replace 1 and 0 with "W" and "L" respectively, 
top.scorers2[, "W"] <- as.numeric(top.scorers2[, "W"])
for (i in 1:nrow(top.scorers)) {
  if (top.scorers2[i, "W"] == 1) top.scorers2[i, "W"] <- "W"
  if (top.scorers2[i, "W"] == 0) top.scorers2[i, "W"] <- "L"
}
top.scorers2[, "W"] <- as.character(top.scorers2[, "W"])

# Correlation test
cor.test(top.scorers$W, top.scorers$FGA)
cor.test(top.scorers$W, top.scorers$FG.percentage)

# Linear regression
# summary(lm(FINAL_MARGIN ~ FGA + LOCATION, data = top.scorers)) # Final margin ~ FGA and location
# summary(lm(FINAL_MARGIN ~ FG.percentage + LOCATION, data = top.scorers)) # Final margin ~ FG% and location
# summary(lm(FINAL_MARGIN ~ FG.percentage + FGA + LOCATION, data = top.scorers)) 

# Logistic regression
model <- glm(W ~ FGA + FG.percentage, data = top.scorers)
summary(model)
anova(model)

```

```{r}
# Find out "special" players by t-test
# Russell Westbrook
t.test(top.scorers$FGA[top.scorers$player_name == "russell westbrook" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "russell westbrook" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "russell westbrook" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "russell westbrook" & top.scorers$W == "0"])
# Gordon Heyward
t.test(top.scorers$FGA[top.scorers$player_name == "gordon hayward" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "gordon hayward" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "gordon hayward" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "gordon hayward" & top.scorers$W == "0"])
# Kawhi Leonard
t.test(top.scorers$FGA[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "0"])
# Mnta Ellis
t.test(top.scorers$FGA[top.scorers$player_name == "mnta ellis" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "mnta ellis" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "mnta ellis" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "mnta ellis" & top.scorers$W == "0"])
# Lebron James
t.test(top.scorers$FGA[top.scorers$player_name == "lebron james" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "lebron james" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "lebron james" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "lebron james" & top.scorers$W == "0"])

special.list <- c("gordon hayward", "russell westbrook", "kawhi leonard")
special <- shot.stats[shot.stats$player_name %in% special.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")]
special2 <- shot.stats[shot.stats$player_name %in% special.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")]
special2[, "W"] <- as.numeric(special2[, "W"])
for (i in 1:nrow(special2)) {
  if (special2[i, "W"] == 1) special2[i, "W"] <- "W"
  if (special2[i, "W"] == 0) special2[i, "W"] <- "L"
}

ggplot(special2) + geom_boxplot(aes(x = player_name, y = FGA, colour = W))
ggplot(special2) + geom_boxplot(aes(x = player_name, y = FG.percentage, colour = W)) 

special.model <- glm(W ~ FGA + FG.percentage, data = special)
summary(special.model)
anova(special.model)

```

##Defender Proximity Analysis  
###Closest Defender Distance vs Shot Accuracy
####Introduction  
This analysis would calculate whether there was any significant effect from closest defender distance from a shooter with the shot outcome. The hypothesis is the further a defender from the shooter, then it will be more likely to increase the chance of scoring. This is because the shooter is practically in "free" condition without any physical interference.  

###Methods  
The steps to calculate this measurement are as follows:  
  1. Assign shot result to determine whether the shot is succeed (1) or missed (0)  
  2. Select distinct of **all** closest defender distance  
  3. Count the occurence fOr every distance  
  4. Calculate how many succesfull shot scored from every distance point  
  5. Calculate accuracy by dividing successfull shot scored with distance occurence for every defender distance point  
  6. Plot the result
```{r}
#Calculate accuracy against defender distance
#Group the defender distance level
distance_level <- as.data.frame(table(factor(df[, "CLOSE_DEF_DIST"])))
head(distance_level)

#Calculate how many times players scored in every defender distance
for (i in 1:nrow(distance_level)){
  distance_level[i, "SCORED"] <- sum(df[df[, "CLOSE_DEF_DIST"] == distance_level[i, "Var1"], "FGM"])
}

#Calculate shooting accuracy for each distance
distance_level$Accuracy <- round(distance_level$SCORED / distance_level$Freq, 4)

#Plotting the result
library(ggplot2)
library(scales)
ggplot(data = distance_level, aes(x = distance_level$Var1, y = distance_level$Accuracy)) +
  geom_point(aes(x = distance_level$Var1, y = distance_level$Accuracy)) +
  scale_y_continuous(labels = percent, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0), limits = c(0, 1)) +
  scale_x_discrete("Closest Defender Distance", breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24)) +
  geom_smooth() +
  ylab("Shooting Accuracy (%)") +
  ggtitle("Closest Defender Distance vs Shooting Accuracy")

```
###Plot Result
  The explanation from the plot above are as follows:   
  1. If the defender stands really close to the shooter (0 to 2 feet), the accuracy varied between **42%** to **50%**  
  2. If the defender distance range from 2 to 4 feet, the accuracy rate for this distance range from **44%** to **49%**  
  3. If the defender distance range from 4 to 6 feet, the accuracy rate for this distance range from **41%** to **46%**
  4. If the defender distance range from 6 to 8 feet, the accuracy rate for this distance range from **37%** to **42%**
  5. If the defender distance range from 8 to 10 feet, the accuracy rate for this distance range from **37%** to **54%**
  6. For defender distance more than 10 feet up until 16 feet, the accuracy varies greater than previous distance range, starting from **33%** to **60%**.  
  7. For the distance greater than 16 feet, the data varies between **0%** (no shots scored from that distance) to **100%** (certain successfull shot from that distance)  

  Next analysis will be calculated from correlation test. If the analysis included **all** of the data points for every distance, the correlation result would be as follows:
```{r}
#change distance level to numeric type for correlation test function
distance_level$Var1 <- as.numeric(distance_level$Var1)
distance_level$Var1 <- distance_level$Var1 * 0.1 - 0.1 #to keep the distance point as it is

#populate data points from data frame
distanceZerotoAll <- c()
accuracyDist1 <- c()
for (i in 0:nrow(distance_level)){
  distanceZerotoAll <- c(distanceZerotoAll, distance_level[i, "Var1"])
  accuracyDist1 <- c(accuracyDist1, distance_level[i, "Accuracy"])
}

#combine data frame
dfZerotoAll <- data.frame(distanceZerotoAll, accuracyDist1)

#calculate correlation
cor.test(dfZerotoAll$distanceZerotoAll, dfZerotoAll$accuracyDist1)
```
###Correlation Test Result  
  The correlation test result produced slightly high number of correlation between defender distance with shooting accuracy for all shot distance attempt in the last seasons's NBA (0.59). If the findings made only based on this number only, there would be obvious that further defender distance will **automatically** increase shooting accuracy. However, after the analysis went into smaller piece of distance, ther result will be difference. For example, for distance range between 0 (zero) to 8 feet, the correlation measurement will be as follows:  
  
```{r}
#populate data from data frame
distanceZerotoEight <- c()
accuracyDist2 <- c()
for (i in 0:80){
  distanceZerotoEight <- c(distanceZerotoEight, distance_level[i, "Var1"])
  accuracyDist2 <- c(accuracyDist2, distance_level[i, "Accuracy"])
}

#combine data frame
dfZerotoEight <- data.frame(distanceZerotoEight, accuracyDist2)

#calculate correlation
cor.test(dfZerotoEight$distanceZerotoEight, dfZerotoEight$accuracyDist2)
```
  As the analysis shown, the correlation measurement between 0 (zero) to 8 feet would be negative (-0.40). This result was different with the previous calculation done for all data points (0.59).
  
###Discussion  
  As the analysis shown, the accuracy rate of every player in the last season was somehow **affected** by the defender distance for certain range. For defender distance starting from 0 (zero) to 8 (eight) feet For the distance greater than 16 feet, the data varies between 0% (no shots scored from that distance) to 100% (certain successfull shot from that distance). It is also shown from the dataset that only small attempt of shots were made from further defender distance affecting the accuracy calculation result. However, from the correlation perspective, the result would be different if the analysis included all of the data points versus only included short distance data points. This was arguably because further defender distance did not implied shooter distance from the basket is nearer to improve the accuracy and also there were not many players to perform shooting attempt automatically although their opponent was standing far from the shooter

###Limitations  
  As the dataset did not hold many data points for more than 20 feet defender distance, the accuracy analysis for these distances are limited. The analysis could be enhanced further by including additional season data. That way, there will be more data point for further distance and possibly would produce stronger pattern as the short distance shown.  
  
###Shooting Distance vs Shot Accuracy
####Introduction  
This analysis would calculate whether was there any significant effect from shooting distance from basket with the shot outcome. The hypothesis is the further a shooter from the basket, then the success rate would be decreased. This was because when the shooter was practically in closer shooting range, the shooter shooting's result would be more accurate.  

###Methods  
The steps to calculate this measurement are as follows:  
  1. Assign shot result to determine whether the shot is succeed (1) or missed (0)  
  2. Select distinct of **all** shooting distance  
  3. Count the occurence fOr every distance  
  4. Calculate how many succesfull shot scored from every distance point  
  5. Calculate accuracy by dividing successfull shot scored with particular distance occurence for every shooting distance point  
  6. Plot the result
```{r}
#Calculate accuracy against shooting distance
#Group the shooting distance level
shooting_distance_level <- as.data.frame(table(factor(df[, "SHOT_DIST"])))
head(shooting_distance_level)

#Calculate how many times players scored in every shooting distance
for (i in 1:nrow(shooting_distance_level)){
  shooting_distance_level[i, "SCORED"] <- sum(df[df[, "SHOT_DIST"] == shooting_distance_level[i, "Var1"], "FGM"])
}

#Calculate shooting accuracy for each distance
shooting_distance_level$Accuracy <- round(shooting_distance_level$SCORED / shooting_distance_level$Freq, 4)

#Plotting the result
library(ggplot2)
library(scales)
ggplot(data = shooting_distance_level, aes(x = shooting_distance_level$Var1, y = shooting_distance_level$Accuracy)) + geom_point(aes(x = shooting_distance_level$Var1, y = shooting_distance_level$Accuracy)) + scale_y_continuous(labels = percent, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0), limits = c(0, 1)) + scale_x_discrete("Shooting Distance", breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48)) + geom_smooth() + ylab("Shooting Accuracy (%)") + ggtitle("Shooting Distance vs Shooting Accuracy")

```

###Plot Result
  The explanation from the plot above are as follows:   
  1.  If the shooter stands really close to the basket (0 to 2 feet), the accuracy varied between **62%** to **68%**  
  2.  If the shooting distance range from 2 to 4 feet, the accuracy rate for this distance range from **61%** to **67%**  
  3.  If the shooting distance range from 4 to 6 feet, the accuracy rate for this distance range from **44%** to **58%**  
  4.  If the shooting distance range from 6 to 8 feet, the accuracy rate for this distance range from **38%** to **51%**  
  5.  If the shooting distance range from 8 to 10 feet, the accuracy rate for this distance range from **35%** to **42%**  
  6.  If the shooting distance range from 10 to 12 feet, the accuracy rate for this distance range from **34%** to **42%**  
  7.  If the shooting distance range from 12 to 14 feet, the accuracy rate for this distance range from **37%** to **47%**  
  8.  If the shooting distance range from 14 to 16 feet, the accuracy rate for this distance range from **33%** to **51%**  
  9.  If the shooting distance range from 16 to 18 feet, the accuracy rate for this distance range from **37%** to **48%**  
  10. If the shooting distance range from 18 to 24 feet, the accuracy rate for this distance range from **33%** to **43%**  
  11. If the shooting distance range from 24 to 28 feet, the accuracy rate for this distance range from **18%** to **38%**  
  12. For shooting distance more than 28 feet, the accuracy varies greater than previous distance range, starting from **0%** (no shots scored from that distance) to **50%**  

  Next analysis will be calculated from correlation test. If the analysis included **all** of the data points for every distance, the correlation result would be as follows:  
```{r}
#change distance level to numeric type for correlation test function
shooting_distance_level$Var1 <- as.numeric(shooting_distance_level$Var1)
shooting_distance_level$Var1 <- shooting_distance_level$Var1 * 0.1 - 0.1 #to maintain distance data point as it is

#populate data for every shooting distance
shootingDistanceZerotoAll <- c()
shootingAccuracyDist1 <- c()
for (i in 0:nrow(shooting_distance_level)){
  shootingDistanceZerotoAll <- c(shootingDistanceZerotoAll, shooting_distance_level[i, "Var1"])
  shootingAccuracyDist1 <- c(shootingAccuracyDist1, shooting_distance_level[i, "Accuracy"])
}

dfShootingZerotoAll <- data.frame(shootingDistanceZerotoAll, shootingAccuracyDist1)
cor.test(dfShootingZerotoAll$shootingDistanceZerotoAll, dfShootingZerotoAll$shootingAccuracyDist1)
```
###Correlation Test Result  
  The correlation test result shown strong negative correlation between shooting distance and shooting accuracy (-0.87). This meant that for all data points, the further a shooter from the basket, it was unlikely the shooter's attempt was success, regardless who was the shooter. However, if the correlation test taken for certain range distance based on the diagram, for example range from 10 feet to 20 feet, the correlation result would be different as follows:

```{r}
#populate data for shooting distance in range 10 to 20 feet
shootingDistance10to20 <- c()
shootingAccuracyDist2 <- c()
for (i in 100:200){
  shootingDistance10to20 <- c(shootingDistance10to20, shooting_distance_level[i, "Var1"])
  shootingAccuracyDist2 <- c(shootingAccuracyDist2, shooting_distance_level[i, "Accuracy"])
}

dfShooting10to20 <- data.frame(shootingDistance10to20, shootingAccuracyDist2)
cor.test(dfShooting10to20$shootingDistance10to20, dfShooting10to20$shootingAccuracyDist2)
```
  The second correlation test produced a small positive correlation between range 10 to 20 feet (0.11). This result was different with previous measurement (-0.87)  
  
###Discussion  
  Based on the diagram and correlation, it can be concluded that although the shooting distance would directly affect shooting accuracy, but the relationship between these variables are not perfectly linear. This was shown in the diagram where there was a relatively **similar** shooting accuracy for shots taken from 10 feet until 20 feet, regardless the shooter's performance. And for the success rate in longer distances, it could be arguably inferred as the shooters tried to attempt in closing game time (buzzer beater) when the shot clock or game clock nearly reach zero.    

###Limitations  
 Since the dataset mostly return 0% for shooting distance greater than 30 feet, it would better if the dataset could be enriched with previous season statistics, or even the last 10 seasons to exercise in more detail about the pattern for long distance shots attempt.  
  
##Hot Hand Theory
###Introduction
  The analysis aims to show the effect of the 'hot hand theory' on NBA players. The analysis is based on the hypothesis that a shooter with a hot hand will have shots that are not independent of one another. If the shooter makes his first shot, the probability of making his next shot is higher.

###Methods
The steps to approximate this question are as follows:
  1. Calculate streaks achieved in all games and from all players
  2. Categorize streaks per player and game, focusing on the 3 players with the top 3 performances in terms of points
  3. Extract zeros and keep only streaks above 1
  4. Visualise streaks' length distribution - barrplots
  5. Visualise streaks' length via boxplot
  6. Calculate the shooting percentage of the 3 players 
  7. Create a sample independent shooter setting as shooting percentage the real player's shooting percentage
  8. Compare distributions of sample and real player 

```{r}

#From 'FGM' column we have that 1 represents a basket made and 0 represents a basket missed
#Define the length of a shooting streak to be the number of consecutive baskets made until a miss occurs
#Create a function that gives us a vector with the number of total streaks(from all players and all games)
number_of_streaks <- function(x) {
  x <- c(0, x, 0)
  which_zero <- which(x == 0)
  streak <- diff(which_zero) - 1
  streak
}

number_of_streaks(df$FGM)

#Summary of total points
ptssum<- cast(df1, GAME_ID1+ player_id + player_name  ~ PTS); head(ptssum)
#creating "total points per player, per game" column
ptssum$totalpts<- ptssum[,"2"]*2 + ptssum[,"3"]*3

pttsum2<-ptssum[order(ptssum$totalpts,decreasing=TRUE),]


#Set a new data frame for the 3 players with best performances(higher points)
best_players_df <- head(pttsum2, 3)

#Create a function that gives us a vector of streaks for a specific player and game
player_and_game <- function(x, y) {
   player <- df[df[, 'player_id'] == x & df[,'GAME_ID1'] == y, 'FGM']
   number_of_streaks(as.vector(player))
}
#For the first player and game try:
#player_and_game('202681', '21400681')


#Create a list that gives us the streaks of each player and game (5 best performances)
streak_per_player <- list()
j <- 1
for(i in best_players_df$player_id) {
   streak_per_player[[j]] <- player_and_game(i, best_players_df[ourtable[, 'player_id'] == i, 'GAME_ID1'])
   j <- j + 1
}
streak_per_player

#Remove 0 from streak_per_player in order to show only the streaks achieved
streak_per_player[[1]] <- streak_per_player[[1]][streak_per_player[[1]] != 0]
for(i in 1:length(streak_per_player)) {
  streak_per_player[[i]] <- streak_per_player[[i]][streak_per_player[[i]] != 0]
}
streak_per_player
```

###Barplots
```{r}

#Create a data frame for the strikes of each one of the 3 players (cannot create a data frame including all of them, because each list has different length)
player1_df <- data.frame('streaks' = streak_per_player[[1]])
player2_df <- data.frame('streaks' = streak_per_player[[2]])
player3_df <- data.frame('streaks' = streak_per_player[[3]])

#Show distribution for each player's streak lengths
gg1 <- ggplot(data = player1_df, aes(x = streaks)) + geom_bar(fill = 'brown') + labs(title = 'Kyrie Irnving')
gg2 <- ggplot(data = player2_df, aes(x = streaks)) + geom_bar(fill = 'red') + labs(title = 'Mo Williams')
gg3 <- ggplot(data = player3_df, aes(x = streaks)) + geom_bar(fill = 'blue') + labs(title = 'Klay Thompson')
grid.arrange(gg1, gg2, gg3, ncol = 3)
```

####Barplot result
  The distribution of the three players is unimodal and left skewed. There are shown some extremely long shooting streaks made(i.e. Klay Thompson with 13 shots in a row).  

###Boxplots

```{r}
#Create a boxplot for each player's streak lengths 
attach(mtcars)
par(mfrow=c(1, 3))
boxplot(player1_df$streaks, main = 'Kyrie Irnving')
boxplot(player2_df$streaks, main = 'Mo Williams')
boxplot(player3_df$streaks, main = 'Klay Thompson')
```

```{r}
#Kyrie Irnving
summary(player1_df$streaks)
IQR(player1_df$streaks) 
```
#### Outcome for Kyrie Irnving:

  1. The typical length of a streak is 1 (median = 1)
  2. The Interquartile Range is 1 
  3. Streak length of 6 is unusually high compared to the rest of the distribution
  
```{r}
#Mo Williams
summary(player2_df$streaks)
IQR(player2_df$streaks)
```

#### Outcome for Mo Williams

  1. The typical length of a streak is 1.5 (median = 1.5)
  2. The Interquartile Range is 1
  3. Streak length of 4 is unusually high compared to the rest of the distribution

```{r}
#Klay Thompson
summary(player3_df$streaks)
IQR(player3_df$streaks)
```

#### Outcome for Klay Thompson

  1. The typical length of a streak is 8 (median = 8)
  2. The Interquartile Range is 5
  3. There is a streak of length 13 (max = 13)

### Plots Result

  The distribution of all players is left skewed and all of them (especially player3) have some long shooting streaks. In order to prove/disprove the hot hand theory,  the examination of the indipendence of the shots is required. If each shot that a player takes is independent of the next shot, then the player has the same probability of hitting each shot regardless of the previous shot. If each shot that a player takes is dependent of the next shot, then the probability of making the next shot is higher - hot hand. Sampling an independent shooter having the same shooting percentage with the real one and comparing his distribution with real player's distribution gives further insight in the specific aera. 

```{r}
#Find the shooting percentage for each of the 3 players
j <- 1
shooting_percentage <- list()
for(i in best_players_df$player_id) {
  shooting_percentage[j] <- sum(df[df[, 'player_id'] == i, 'FGM']) / nrow(df[df[, 'player_id'] == i, ])
  j <- j + 1
}
shooting_percentage
```

###Kyrie Irving
```{r}
###PLAYER 1 VS SAMPLE PLAYER###
#Simulation - create a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter1 
set.seed(974)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[1]]), replace = TRUE, prob = c(shooting_percentage[[1]], 1 - shooting_percentage[[1]]))
simul_shooter


#Set 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for (i in 1:length(simul_shooter)) {
   if (simul_shooter[i] == 'made') {
     simul_shooter[i] <- 1
   } else if (simul_shooter[i] == 'missed') {
     simul_shooter[i] <- 0
   }
}
simul_shooter

#Use previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Create new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[1]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)

#Compare barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'red') + labs(title = 'Kyrie Irving')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result
  After running many times the sample shooter, there are times that the distributions of sample and real shooter are quite similar. As a consequence, it can be concluded that Mo Williams does not have a hot hand.

### Mo Williams
```{r}
###PLAYER 2 VS SAMPLE PLAYER###
#Simulation - create a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter1 
set.seed(572)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[2]]), replace = TRUE, 
                        prob = c(shooting_percentage[[2]], 1 - shooting_percentage[[2]]))
simul_shooter


#Set 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for(i in 1:length(simul_shooter)) {
   if(simul_shooter[i] == 'made') simul_shooter[i] <- 1
   else if(simul_shooter[i] == 'missed') simul_shooter[i] <- 0
}
simul_shooter

#Use previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Create new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[2]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)

#Compare barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'green') + labs(title = 'Mo Williams')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result

  After running many times the sample shooter, there are times that the distributions of sample and real shooter are quite similar. As a consequence, it can be concluded that Mo Williams does not have a hot hand.

###Klay Thompson
```{r}
###PLAYER 3 VS SAMPLE PLAYER###
#Simulation - create a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter1 
set.seed(57)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[3]]), replace = TRUE, 
                        prob = c(shooting_percentage[[3]], 1 - shooting_percentage[[3]]))
simul_shooter


#Set 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for(i in 1:length(simul_shooter)) {
   if(simul_shooter[i] == 'made') simul_shooter[i] <- 1
   else if(simul_shooter[i] == 'missed') simul_shooter[i] <- 0
}
simul_shooter

#Use previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Create new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[3]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)

#Compare barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'brown') + labs(title = 'Klay Thompson')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result

  Klay Thompson is an exception making 13 shots in a row. There is no such distribution in the sample, so it coulb be assumed that he is likely to have a hot hand. Further statistical analysis (logistic regression) should be done in order to reach a conclusion.


```{r}
#Regression Analysis

df1$GAME_CLOCK <- as.numeric(df1$GAME_CLOCK)

df1$AWAY_TEAM <- as.character(df1$AWAY_TEAM)

linreg_fgm <- lm(FGM ~ LOCATION + W + FINAL_MARGIN + SHOT_NUMBER + PERIOD + GAME_CLOCK + SHOT_CLOCK+ DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSEST_DEFENDER_PLAYER_ID + CLOSE_DEF_DIST + player_id + WINNER, df1)

summary(linreg_fgm)

linreg_fgm2 <- lm(FGM ~ FINAL_MARGIN + SHOT_NUMBER + PERIOD + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSE_DEF_DIST + player_id, df1 )


summary(linreg_fgm2)

```


#Conclusion


#References
=======

```{r}


```



>>>>>>> f09f38865de02686a7fc1576fd100ecf266b031c
---