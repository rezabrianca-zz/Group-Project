---
title: "MSF_Groupwork-NBA_shotlog"
author: "Team_9"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
```
##Report produced by: Justin Leiendecker, Alexander Romanenko, Artmeis Tomadaki-Balomenou, Zijun Wei, Reza Brianca Widodo  
##Date submitted: 16/10/2016

***



##Introduction

The purpose of this report is to analyse the chosen dataset and to produce meaningful results using statistical and mathematical analysis. These analyses have been conducted using RStudio software. This report will focused on analysis of a number of areas, demonstrate how the analysis has been conducted, discusses theory used, demonstrate and evaluate produced results. In addition, where relevant, this report will highlight potential areas of future research. 

The chosen dataset for this report is a summary of shots made during NBA season 2014-2015. The following areas of research have been selected:

** TO GET UPDATED AS A FINAL STEP**

**1. Team related**
  a. Home Advantage analysis  
  b. Effect of rest on teams' performance  
  
**2. Player related**
  a. Effects on Accuracy  
  b. Shot Clock Pressure  
  c. Fatigue Effect (Quarter Accuracy Rate)    
  d. Game result impact by field goal attempts  
  e. Defender Proximity Analysis  
  f. Shooting Distance vs Shot Accuracy   
  g. Hot Hand Theory  


###Dataset Description:  
  

  Data on shots taken during the NBA 2014-2015 season for regular matches throughout the year. The data comprise of 128,609 rows and 22 columns with 16 MB data size with several value in some column missing. The column titles are generally self-explanatory. It has the following data:   

Data  contains full set of shot attempts by each team/player during the NBA 2014-2015 season for regular matches throughout the year. The data comprise of 128,609 rows and 22 columns with. The column titles (variables) are as follows:   
    1.  Match ID  
    2.  Match date and names of contestants  
    3.  Location: home and away  
    4.  Match result  
    5.  Final score difference  
    6.  shot number  
    7.  FGM: Shot result: success or miss 
    8.  Type of shot attempt (2 points or 3 points)  
    9.  Quarter number (1 to 4, or higher for overtime)  
    10. Game clock for each quarter when the shot has been made 
    11. Shot clock (time left for a shot)  
    12. Name and ID of a player who took the shot  
    13. Shot distance from basket  
    14. Name and ID of the nearest defender  
    15. Distance from the nearest defender  
  
 The data has been acquired from [Kaggle](https://www.kaggle.com/dansbecker/nba-shot-logs) website on 30 September 2016.  

###Dataset Strengths  
    
<<<<<<< HEAD
=======
  The dataset comprises of comprehensive observational data to start to work with. In general, the dataset has only a small percentage of missing value (0.19%) so there was not need to remove or assign many data points to default values. Since the column name is not ambiguous it was really helpful to understand the dataset right from the beginning. 

>>>>>>> 6b2c354a4bdb097e3c4f65d733da52df1bac024e
  The dataset comprises of comprehensive observational data which enables efficient analysis without extensive 'clean up' of the data. The dataset only have small percentage of missing value (0.19%), therefore there is no need to remove or assign numerous data points to default values. The fact that initial dataset meant that only a small number of additional columns had to be added (see data clean-up part of the code for details. 


###Dataset Limitations  
  There are several limitations of the dataset:  
    1. The dataset consists only 1 year NBA season stats (2014-2015)  
    2. The dataset comprise only the data for regular season matches  
    3. The playoff and other matches during the year are not included
    4. The dataset does not include information on free throw shots
    5. The dataset does not include final scores of the games

***

#Analysis


```{r, eval=FALSE, include=FALSE}
# Installing libraries
install.packages('reshape')
install.packages('gridExtra')

```


```{r, include=FALSE}
# Calling libraries
library(reshape)
library(ggplot2)
library(gridExtra)
library(plyr)

```


```{r, include=FALSE}
###Data clean-up

df <- read.csv("shot_logs.csv")  #assigning the dataframe to 'df' variables
 #telling R that this is the dataframe we'll be working with (eliminating the need to use df$ for variables)

df1 <- read.csv("shot_logs1010.csv")

# replacing W/L in column "W" with 1/0 (1 for win, 0 for loss)
df[, "W"] <- as.character(df[, "W"])

for (i in 1:nrow(df)) {
  if (df[i, "W"] == "W") df[i, "W"] <- 1
  if (df[i, "W"] == "L") df[i, "W"] <- 0
}

df[, "W"] <- as.numeric(df[, "W"])
```

```{r, include=FALSE}
#adding columns for names of 'home' and 'away' teams. In addition, WINNER column tells which team won
df[, "MATCHUP"] <- as.character(df[, "MATCHUP"])
df[, "W"] <- as.character(df[, "W"])

for (i in 1:nrow(df)) {
  if (df$LOCATION[i] == "H") {
    df$HOME_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[5]
    df$AWAY_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[7]
    if (df$W[i] == "W") df$WINNER[i] <- "HOME" 
    if (df$W[i] == "L") df$WINNER[i] <- "AWAY"
  }
  if (df$LOCATION[i] == "A") {
    df$HOME_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[7] 
    df$AWAY_TEAM [i] <- unlist(strsplit(df$MATCHUP[i], " "))[5]
    if (df$W[i] == "L") df$WINNER[i] <- "HOME"  
    if (df$W[i] == "W") df$WINNER[i] <- "AWAY"
  }
}

#adding a column 'DATE'
df1[, "MATCHUP"] <- as.character(df1[, "MATCHUP"])
for (i in 1:nrow(df1)) df1$DATE[i] <- as.character(as.Date(unlist(strsplit(df1$MATCHUP[i], " -"))[1], format = "%B %d, %Y"))

#creating a column for 'TEAM'. This column relates to the team whose player made a shot described by the dataframe
for (i in 1:nrow(df1)) df1$TEAM[i] <-unlist(strsplit(df1$MATCHUP[i], " "))[5]

#preparing dataframe for rest days calculation
df1$BLANK2<-""
restdays2 <- cast(df1, TEAM + DATE + LOCATION + W + FINAL_MARGIN ~ FGM)
restdays2$DATE<- as.Date(restdays2$DATE)

```



## Home Advantage analysis
###Introduction

This area of analysis focuses on investigation of whether playing at 'home' gives the team advantage comparing to when playing 'away'. Esssentially, this analysis focuses on effect of the game location (home/away) on winning ratio.

<<<<<<< HEAD
The NULL Hypothesis: Teams playing at home is more likely to win then when playing away. 
=======
The NULL Hypothesis: Analysis of means for home and away wins does not show any significant difference 
>>>>>>> 1b25eccc761c66f3124934ae91783c80cf6ab6fa

###Methods
Steps to test the hypothesis are as follows:  
    1. Calculate a total number of games, which has been won by a home or away team
    2. Compare the total win numbers to identify whether home advantage is evident using means of the variables
    3. Extend the analysis to review of the home/away wins on a team level 
    4. Plot the team level data 
    5. Perform a t-test (p .05) to examine whether there is a difference in the means between teams winning at home and teams winning away
    6. Linear regression with Final margin as dependent variable and Location as independent variable to examine whether playing at home results predicts a higher final margin

The graph below shows descriptive statistics for home/away wins: 



```{r, include=FALSE}
#preparing a dataframe for home advantage analysis
advdf <- cast(df1, GAME_ID1 + HOME_TEAM + AWAY_TEAM + WINNER ~ W)

#table showing a number of games won by home and away teams in the whole season
table(advdf$WINNER)

#home wins:
hh <- sum(advdf$WINNER == "HOME")
#Away wins:
aw <- sum(advdf$WINNER == "AWAY")

#percentage of home team winning: 
round(hh / (hh + aw), 4)
round(aw / (hh + aw), 4)
```



```{r, include=FALSE}
#preparing a dataframe for analysis of games when a team played at home 
advdf1 <- cast(advdf, HOME_TEAM ~ WINNER); names(advdf1)[1] <- "TEAM"
advdf1$WIN_PCT_HOME <- round(advdf1$HOME / (advdf1$HOME + advdf1$AWAY), 2)

#preparing a dataframe for analysis of games when a team played at away 
advdf2 <- cast(advdf, AWAY_TEAM ~ WINNER); names(advdf2)[1] <- "TEAM"
advdf2$WIN_PCT_AWAY <- round(advdf2$AWAY / (advdf2$HOME + advdf2$AWAY), 2)

#merging two dataframes together to enable the effective analysis of win ratios for teams playing at home and away.
advdf3 <- merge (advdf1, advdf2, by ="TEAM")

#ordering the dataframe by win percentage at home.
advdf3 <- advdf3[order(advdf3$WIN_PCT_HOME, decreasing = TRUE),]

#ordering factors of the dataframe by win percentage at home.
advdf3$TEAM <- factor(advdf3$TEAM, levels = advdf3$TEAM[order(-advdf3$WIN_PCT_HOME)])

#creating a column which shows a difference between home and away winning percentage rate
advdf3$WIN_PCT_DIFF<- advdf3$WIN_PCT_HOME - advdf3$WIN_PCT_AWAY


#t tests

t.test(advdf3$AWAY.y, advdf3$HOME.x)
```


```{r, echo=FALSE}
#plot showing home and away win ratio per team
ggplot(advdf, aes(x = advdf$WINNER)) + geom_bar(aes()) + ylab("game count") + xlab("winner")
```




<<<<<<< HEAD
###Results
Table 1: Proportion of total games split by Location win factor
=======
###Findings
**Table 1**: Proportion of total games split by Location win factor
>>>>>>> 1b25eccc761c66f3124934ae91783c80cf6ab6fa

X     | Home Win | Away Win
----- | -------- | ---
Game  | 506      | 398
Perc  | 55.97%   | 44.03%

**Tables 2 & 3**: Winning ratio of teams playing at home vs games playing away 

Team     | GSW | ATL | POR | MEM | SAS | CLE | HOU | LAC | OKC | DAL | NOP | WAS | TOR | CHI | MIL  
------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----
Win % HOME  |   93| 88  | 81  | 77  | 75  | 72  | 72  | 72  | 71  | 68  | 68  | 68  | 66  | 59  | 59 
Win % AWAY  |   69| 71  | 54  | 67  | 50  | 53  | 61  | 57  | 42  | 61  | 40  | 43  | 59  | 66  | 45 
Win % Diff  |   24| 17  | 27  | 10  | 25  | 19  | 11  | 15  | 29  | 7   | 28  | 25  | 7   | -7  | 14


Team     | PHX | IND | BOS | CHA | UTA | DEN | BKN | SAC | MIA | DET | LAL | ORL | PHI | NYK |MI 
------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----
Win % HOME  | 57  | 52  | 48  | 47  | 45  | 42  | 41  | 41  | 39  | 38  | 31  | 30  | 28  | 27  | 26 
Win % AWAY  | 47  | 35  | 32  | 41  | 35  | 30  | 44  | 30  | 48  | 39  | 23  | 31  | 16  | 14  | 18 
Win % Diff  | 10  | 17  | 16  | 6   | 10  | 12  |-3   | 11  |-9   |-1   |    8|   -1|   12|   13| 8


```{r, echo=FALSE}
#plot showing home and away win ratio per team
ggplot(advdf3, aes(x = TEAM)) + geom_point(aes(y = WIN_PCT_HOME, col = "wins at HOME")) + geom_point(aes(y = WIN_PCT_AWAY, col = "wins  AWAY")) + ylab("Win ratio") + xlab("Team Names")
```

The plot shows that out of 30 teams:
  25 teams have won more games at home than away
  3 teams have won more games away than at home
  2 teams home and away win ratios are almost equal (difference of less than or equal to 1%)


The T-test used to verify the differences in the means seen in the plot reached significance, t(58) = -2.39, p = .02.

###Regression analysis

```{r, include=FALSE}
margreg<- lm(FINAL_MARGIN ~ LOCATION, restdays2)
summary(margreg)
```

**Table 4**: Regression analysis for the effect of location and rest days on final score margin

  X         |Estimate |Std. Error| t value| Pr(>t)    
------------|---------|--|--|------------------------
(Intercept) |-2.12919 |   0.51589 | -4.127 |3.84e-05 ***
LOCATIONH   |4.28556  |  0.63881  | 6.709 |2.63e-11 ***
rest        |-0.01129 |   0.25992 | -0.043 |   0.965 
  

Adjusted R-squared = 0.02392

###Discussion

The analysis shows that there is a clear evidence that a team playing at home is more likely to win with an average win probability of 55.97%. The same conclusion is evident from the analysis conducted on a team level where 25 teams are winning more games at home than away. The results show that the NULL hypothesis should be rejected as a team playing at home is more likely to win than an away team. Linear regression analysis shows that playing at home gives teams on average additional 4.29 margin points. 

The result of this research also confirms the recent trend of decline in home advantage over the years: probability of a home team winning has reduced from around 65% in 1975-1992 to average of 60.3% in 1993-2011 and to around 58.5% for 2011-14. The analysis demonstrated that the home win ratio went down even further to 56.0% in 2014-2015 season. Based on the literature review this trend could be potentially explained by the following factors (Economist, 2015):

  1. Improvement of travel conditions. This means that when playing away, teams are now more likely to stay at better hotels and fly charterd planes more often than in the past. These changes result in teams being less tired as a consequence of travel and being better physically prepared for the games.
  
  2. Change in style of play in NBA. The game now is more open with less physical contact, which reduces number of fouls and potential impact of 'notorious home-team bias' by referees (Economist, 2015).

***

##Effect of rest on teams' performance

###Introduction

This area of analysis focuses on investigation of whether a number of rest days between games affect the performance and more importantly winning ratio of a team. 

<<<<<<< HEAD
The Null Hypothesis is: By having more restdays rest a team is likely to have a higher winning ratio. 
=======
The Null Hypothesis is: Teams' mean values of wins are not significantly different based on the number of rest days between games 

>>>>>>> 1b25eccc761c66f3124934ae91783c80cf6ab6fa

###Methods

The steps to calculate this measurement are as follows:  
    1. Calculating number of rest days between games for all teams
    2. Calculating ratios for effects of rest days on win/loss
<<<<<<< HEAD
    3. Calculating ratios for effects of rest days on win/loss form home/away
    4. Perform a Chi-square test to examine whether there is a difference in the distributon for games won and games lost for the different restdays
    
=======
    3. Calculating ratios for effects of rest days on win/loss form home/awayCalculating ratios for effects of rest days on win/loss
    4. Run a regression analysis
    5. Discuss the findings of the data

The table below shows descriptive statistics for Rest Days:

**Table 5**: Distribution of number of games per rest days

 Rest Days| Games | Distribution
----------|-------|---
    0  | 427 | 23.62
    1  | 990 | 54.76
    2  | 254 | 14.05
    3  |  59 |  3.26
    4  |  13 |  0.72
    5  |   3 | 0.17
    7  |   6 | 0.33
    8  |  20 | 1.11
    9  |   3 | 0.17
    10 |   3 | 0.17
   1st game of season  |  30|  1.66

The distribution of rest days shows that 92% of games are covered by 0,1 or 2 days of rest and therefore further analysis will only focus on these 3 sections.    
>>>>>>> 1b25eccc761c66f3124934ae91783c80cf6ab6fa

```{r, include=FALSE}


#calulating number of rest days between teams
for (i in 2: nrow (restdays2)) {
  if (restdays2$TEAM[i]==restdays2$TEAM[i-1])
    restdays2$rest[i]<- as.numeric(restdays2$DATE[i] - restdays2$DATE[i-1]-1)
  else 
    (restdays2$rest[i]<- "NA")  
}
restdays2$BLANK<-""

restdays2$rest <- as.numeric (restdays2$rest)

#regression analysis
margreg<- lm(FINAL_MARGIN ~ LOCATION + rest, restdays2)
summary(margreg)


#creating dataframe for total rest days
restdays4<- cast (restdays2, rest ~  W)
colnames(restdays4)<- c( "rest", "L","W") 

#creating a column for total restdays for a team when lost and won to enable calculation of ratios
restdays4$total<-restdays4$L + restdays4$W
restdays4$dist <-   round (restdays4$total * 100 /sum (restdays4$total) ,2)

#plotting distribution of rest days to establish which of the rows should be analysed
restdays4[,c(1,4,5)]
#The distribution of rest days show that 92% of games are covered by 0,1 or 2 days of rest and therefore further analysis will only focus on these 3 sections

restdays4$ L.pct <-   round(restdays4$L*100/(restdays4$L+restdays4$W),2) 
restdays4$ W.pct <-   round(restdays4$W*100/(restdays4$L+restdays4$W),2)

print (restdays4[1:3,c(1,3,7)])

#creating a new dataframe for summary of home/away win losses based on number of rest days.
restdays3<- cast (restdays2, rest ~ LOCATION + W) ; 

#renaming the columns
colnames(restdays3)<- c( "rest", "AL","AW","HL", "HW") 

#caluclating ratios
restdays3$ AL.pct <-   round(restdays3$AL*100/(restdays3$AL+restdays3$AW),2) 
restdays3$ AW.pct <-   round(restdays3$AW*100/(restdays3$AL+restdays3$AW),2)
restdays3$ HL.pct <-   round(restdays3$HL*100/(restdays3$HL+restdays3$HW),2)
restdays3$ HW.pct <-   round(restdays3$HW*100/(restdays3$HL+restdays3$HW),2)

print (restdays3[1:3,c(1,7,9)])


#Testing of rest data
qqqq<-as.matrix(sapply(restdays4, as.numeric))


chisq.test(qqqq[2,], qqqq[3,])




```

###Findings

<<<<<<< HEAD
Table 5: Distribution of number of games per rest days

 Rest Days| Games | Distribution
----------|-------|---
    0  | 427 | 23.62
    1  | 990 | 54.76
    2  | 254 | 14.05
    3  |  59 |  3.26
    4  |  13 |  0.72
    5  |   3 | 0.17
    7  |   6 | 0.33
    8  |  20 | 1.11
    9  |   3 | 0.17
    10 |   3 | 0.17
   1st game of season  |  30|  1.66

The distribution of rest days shows that 92% of games are covered by 0,1 or 2 days of rest and therefore further analysis will only focus on these 3 sections. 
=======
>>>>>>> 1b25eccc761c66f3124934ae91783c80cf6ab6fa

**Table 6**: Win rate split by number of rest days between games

  Rest Days| Number of Wins|Win Percentage
-|-|-
    0| 201| 47.07
    1| 496| 50.10
    2| 137| 53.94


**Table 7**: Win rate split by number of rest days between games and location

  Rest Days| Home Wins Percentage | Away Wins Percentage|
-|-|-
    0|   53.54 |44.33 
    1 | 54.68 |  44.24
    2  | 59.57 | 46.90
 
The Pearson's Chi-Square test failed to reach the level of significance, X2 (36) = 42, p= .23.
 
###Discussion

The analysis demonstrates that overall the winning ratio stays the same with increase in  rest days. However, when looking at invididual restdays the findings are different: back-to-back games have 47.07% winning ratio, 1 day rest increases winning ratio to 50.1% and with 2 days rest the winning ration increases even further to 53.94%.

By extending the analysis to the team level, the results demonstrate similar tendency for home games where winning ratio increased from 53.54% to 54.68% and 59.57% respectively with 0, 1 and 2 days of rest. Somewhat interestingly the analysis of effect of rest days on winning ratio of away games demonstrates that there is hardly any difference between 0 and 1 days of rest (44.33% and 44.24%). However with 2 days of rest teams' average winning ratio increases to 46.90% (2.66% increase). This perhaps could be explained by the fact that teams were able to minimise effect of travelling when having a bigger window between games.

Based on the above, the analysis shows that the null hypothesis should be rejected as there is a clear evidence that the higher rest days correspond to higher winning ratio.

###Further research

To better understand effects of rest and home/away advantage future research should focus on distances the teams have to travel between the games. For example if a team is travelling from one coast to another- it is likely to affect them more comparing to a team from New York 'travelling' to play an away game in New Jersey.

***

##Effects on accuracy

###Introduction

The potential effects of fatigue and stress on the accuracy of shots are investigated in this part of the analysis.

Fatigue in basketball is a broadly analysed topic in physiological research. Latest literature suggests that elite basketball players cope well with the effects of fatigue so it does not affect their shooting kinematics. This results in no difference for their shot accuracy even if the players are fatigued (Erculj and Supej, 2009). This research paper analyses whether these previous findings can be confirmed for the NBA season 2014-2015.  

Regarding the effect of psychological stress on shot accuracy, previous research is not as decisive as for the effects of fatigue. While Ahart(1973, in P.C. Kendall & S.D Hollon (1979) *Cognitive-Behavioral Interventions: Theory, Research, and Procedures*) concluded that stressful events like small or big margins for the game score have an effect on players free-throw accuracy, latest research introducing more controlled conditions states that there is no effect of stress on players shot accuracy (Mascret et al., 2016). The indecisiveness of previous literature led to a deeper analysis in this research paper.


Hypotheses for this area of analysis are:

Fatigue: The Null hypothesis states that there is no significant difference (p < .05) for the shot accuracy in later periods of the game.

Stress: The Null hypothesis states that there is no significant difference (p < .05) for the shot accuracy in more stressful events.


###Methods

In this analysis fatigue was measured as the period of the game, as it can be assumed that the later in the game the higher the fatigue of the players. The descriptive statistics of the shots per period can be seen below. 

```{r, echo=FALSE}
bar.period <- ggplot(df) + geom_bar(aes(x = PERIOD))
bar.period + labs(title = "Number of shots taken per period") + scale_x_discrete(name ="Period", limits=c("1","2","3","4", "5", "6", "7")) + ylab("Number of shots")
```


The steps to test the first hypothesis were as follows:
  1. The overall accuracy for each period was calculated, based on the number of shots made (FGM = 1) and the number of shots taken for the specific period (FGM = 1 & FGM = 0)
  2. This results in a percentage value of shots made for each of the periods
  3. A variable called "Overtime" was introduced to distinguish between periods in the regular game time and overtime
  4. The average accuracy for regular time and overtime was calculated
  5. A T-test was used to examine whether or not these values were significant different at a level of significance of 5%.
  
  
Psychological stress was measured through the remaining time on the shot clock for each shot taken. It was assumed that a player would experience more stress the lower the shot clock goes.

The steps to test the second hypothesis were as follows:
  1. As the shot clock variable contained 5567 missing values, those were excluded from the analysis
  2. To simplify the shot clock variable, decimals were removed from the data so every shot taken was assigned to 0 to 24 seconds left on the shot clock
  3. The overall accuracy for each second was calculated using the FGM variable


```{r, include=FALSE}

### FATIGUe

# accuracy per period

df.acc <- data.frame()
  
for (i in (1:7)){
  df.acc[i, "accuracy"] <- sum(df$PERIOD == i & df$FGM == 1) / sum(df$PERIOD == i)
  df.acc[i, "period"] <- i
  if (df.acc$period[i] <= 4) df.acc[i, "overtime"] <- 0
  if (df.acc$period[i] >= 5) df.acc[i, "overtime"] <- 1
}

regular <- sum(df.acc$accuracy[df.acc$period <= 4])/4
overtime <- sum(df.acc$accuracy[df.acc$period >=5])/3


t.test(df$FGM[df$PERIOD == 1], df$FGM[df$PERIOD == 2])
t.test(df$FGM[df$PERIOD == 2], df$FGM[df$PERIOD == 3])
t.test(df$FGM[df$PERIOD == 3], df$FGM[df$PERIOD == 4])
t.test(df$FGM[df$PERIOD == 1], df$FGM[df$PERIOD == 3])
t.test(df$FGM[df$PERIOD == 2], df$FGM[df$PERIOD == 4])
t.test(df$FGM[df$PERIOD == c(1:4)], df$FGM[df$PERIOD == c(5:7)])


### STRESS
# accuracy for Shot Clock

# dealing with missing values
df1[is.na(df1)] <- 99

acc <- data.frame(seconds.left = c(0:24))

#accuracy for every second
for (i in (0:24)){
  acc[i, "accuracy"] <- (sum(df1$SHOT_CLOCK >= i & df1$SHOT_CLOCK < i + 1 & df1$SHOT_CLOCK != 99 & df1$FGM == 1) / sum(df1$SHOT_CLOCK >= i & df1$SHOT_CLOCK < i + 1 & df1$SHOT_CLOCK != 99))
}

ggplot(acc, aes(x = seconds.left, y = accuracy)) + geom_point() + geom_smooth()



#accuracy for players per second

##simplifying shot clock to seconds left
  
df.acc.players <- cast(df1, player_id + player_name + SHOT_CLOCK ~ FGM)

for (i in (1:nrow(df.acc.players))){
  for (j in (0:24)){
    if (df.acc.players$SHOT_CLOCK[i] >= j & df.acc.players$SHOT_CLOCK[i] < j + 1) df.acc.players[i, "seconds.left"] <- j
    if (df.acc.players$SHOT_CLOCK[i] == 99) df.acc.players[i, "seconds.left"] <- 99
  }
}


df.acc.secondsplayers<- df.acc.players

df.acc.secondsplayers$SHOT_CLOCK <- NULL

colnames(df.acc.secondsplayers)<- c( "player_id", "player_name","X0", "X1","seconds.left") 


df.acc.secondsplayers2 <- ddply(df.acc.secondsplayers, c("player_id", "player_name","seconds.left"), summarise,
X0= sum(X0),
X1= sum(X1))

df.acc.secondsplayers2$acc <-  df.acc.secondsplayers2$X1/(df.acc.secondsplayers2$X0+df.acc.secondsplayers2$X1)

df.acc.secondsplayers2[df.acc.secondsplayers2 == 99] <- NA

df.acc.secondsplayers3 <- data.frame(row.names = c(0:24))
df.acc.secondsplayers3$seconds.left <- c(0:24)

for (i in df.acc.secondsplayers3$seconds.left){
  df.acc.secondsplayers3$acc.top[df.acc.secondsplayers3$seconds.left == i] <- sum(df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "james harden"][!is.na(df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "james harden"])], df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "lebron james"][!is.na(df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "lebron james"])], df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "russell westbrook"][!is.na(df.acc.secondsplayers2$acc[df.acc.secondsplayers2$seconds.left == i & df.acc.secondsplayers2$player_name == "russell westbrook"])])/3}



ggplot(NULL) + geom_smooth(data = df.acc.secondsplayers3, aes(x = seconds.left, y = acc.top, color = "Top Players")) + geom_smooth(data = acc, aes(x = seconds.left, y = accuracy, color = "Average"))


t.test(acc$accuracy, df.acc.secondsplayers3$acc.top)

```

###Results

The accuracies for each period are detailed in the table below. 

**Table 8**: Accuracy per period
Period  | Accuracy
------- | ---------
1       | 46%
2       | 45%
3       | 46%
4       | 44%
5       | 39%
6       | 43%
7       | 37%
regular | 45%
overtime | 40%



The T-tests for period 1 and period 2 was significant, t(65301) = 2.42, p = .015, as well as the T-test for period 3 and 4, t(60757) = 4.24, p < .01. Further the T-test for period 2 and 3 was not significant, t(63843) = -1.53, p = .126, as well as the T-test for period 1 and 3, t(65989) = 0.87, p = .38. 
The T-test for regular time and overtime was highly significant, t(383) = 2.77, p < .01.


The changes in the overall accuracy per second are shown in the graph below.

```{r, echo=FALSE}
graph.acc <- ggplot(acc, aes(x = seconds.left, y = accuracy)) + geom_point() + geom_smooth()

graph.acc + labs(title = "Overall Accuracy per second left on shot clock") + xlab("Seconds left on shot clock") + ylab("Overall Accuracy")
```

### Discussion

The results of the T-tests show a significant difference for the overall accuracy between period 1 and period 2, between period 3 and period 4 and between regular game time and overtime. This means that player have a higher accuracy in periods 1 and 3 than in the following one. As the table 8 shows, the changes in accuracy are minor (from 46% to 44% over the regular game time) and often located on digit-level, so although the changes are significant they are negligible. After all, the Null hypothesis must be rejected as the statistical methods used show differences for accuracy in later periods of the game, but as they are negligible in the regular game time but it can be concluded that accuracy does not suffer for later game periods as long as the game ends in regular time. For games that reach overtime a highly significant drop in the accuracy of over 5% (45% to below 40%) is observale, stating that players are less likely to score in overtime periods that in the regular game time.
This means that elite basketball players cope really well with any occurance of fatigue regarding their shot accuracy on a regular basis. As soon as the game reaches an intensity which is beyond the regular level effects of fatigue can be found leading to lower shot accuracy. 


The effects of psychological stress are highly visible as shown in the graph above. While the accuracy in the first 10 seconds of the shot clock is exceeding the overall accuracy in the regular game time (60-45% vs 45% in regular game time), it declines quite fast in the last 5 seconds of the shot clock (from 42% to 32%), leading to the rejection of the Null hypothesis, that there are no differences in the accuracy for more stressful events. These results imply that as the shot clock runs out, so as the psychological pressure on the shooter increases, their shot performance suffers.


An ad hoc data analysis was undertaken to investigate whether this pattern of stress-inducted accuracy declination can be found as well for "superstar" players. The players were Lebron James, James Harden and Russel Westbrook, chosen because they were the top 3 shooters in the season. Their combined average accuracy per second can be seen in the graphic below. 

```{r, echo=FALSE}

graph2 <- ggplot(NULL) + geom_smooth(data = df.acc.secondsplayers3, aes(x = seconds.left, y = acc.top, color = "Top Players")) + geom_smooth(data = acc, aes(x = seconds.left, y = accuracy, color = "Average"))
graph2 + labs(title = "Comparison - Accuracy per second on shot clock left for Top Players vs Overall Average") + xlab("Seconds left on shot clock") + ylab("Accuracy")

```

The graph shows many similarities for top players to the average graph. The most visual differences are the slightly lower accuracy around the 15 seconds mark for the top players and the much lower decrease below 5 seconds left. Explanations for these differences could be that around the 15 second mark top players feel more obligated to shoot than the average player, even when they are not in the optimal position to do so - leading to lower accuracies. Further it seems like Top players dont get affected by last seconds stress as much as average players. They keep up a quite high accuracy even for the last second of the shot clock (40%). However, as there are many similarities for the accuracy of Top players and average players there must be other things than the accuracy that seperates those two groups. 

### Future research

Future research could focus on this difference between Top players and average players. While this analysis revealed a difference for shot clock pressure it would be interesting to look at more events that induce stress like the margin of the game or the placement in the standings of the own and the enemy team. Further an investigation of the reasons that lead to the higher accuracy would be interesting. Do top players keep up their usual shot kinematics when under pressure while average players dont? Is it a different mindset that helps them to cope better with stress? Or do they simply have a higher stress tolerance as the result of continuous high expectations top players have to endure?

Additionally, further reasons that lead to distinction between top players and average players should be investigated.


###Limitations 


As there are much more shots taken in periods 1 to 4 than in 5 to 7 the differences in the accuracy have to be treat with caution.
The shot clock variable had missing values for 5567 shots, equal to 4.34% of all shots on the dataset, limiting the meaningfulness of the findings in the accuracy per second part. 


## Shooting Percentage Analysis (James)

###Introduction  

The aim of this analysis is to examine whether the top scorer of a team can help his team to win the match when he has a more outstanding performance in terms of both number of shooting attempts and accuracy. The Null hypothesis is that there is no difference regarding the likelyhood of winning if the top scorer of a team has more field goal attempts. The second Null hypothesis is there is no difference regarding the likelyhood of winning if the top scorer of a team has a higher shot percentage than on average. As this is such a niche area research a literature review did not reveal sufficient results so this analysis aims to fill this gap.

###Methods

The measurements are calculated in the following steps:

  1. “Made” and “missed” in “FGM” column were replaced by 1 and 0 respectively.
  2. A new subset was created so that each row contained the player’s name, match details and shooting performance for that player.
  3. The number of attempts and field goal percentage of all players were calculated according to the shooting data. 
  4. The players with most outstanding performances were picked out and another subset was generated for these players.
  5. The correlation (p = .05) between the results of the matches and the performances of top scorers was investigated. 
  6. A logistic regression analysis with the outcome of the match as dependent variable and FGA and percentage of FG made as independent variables was conducted.

```{r, include=FALSE}
# Replace "made" and "missed" with 1 and 0 respectively

df[, "SHOT_RESULT"] <- as.character(df[, "SHOT_RESULT"])
 
for (i in 1:nrow(df)) {
  if (df[i, "SHOT_RESULT"] == "made") df[i, "SHOT_RESULT"] <- 1
  if (df[i, "SHOT_RESULT"] == "missed") df[i, "SHOT_RESULT"] <- 0
}

df[, "SHOT_RESULT"] <- as.numeric(df[, "SHOT_RESULT"])

```

```{r, include=FALSE}
# Reshape the dataframe

shot.stats <- cast(data = df1, GAME_ID1 + HOME_TEAM + AWAY_TEAM + LOCATION  + W + player_name + FINAL_MARGIN ~ FGM)

# Field Goal Attempts

shot.stats[, "FGA"] <- NA
for(i in 1:nrow(shot.stats)){
  shot.stats[i, "FGA"] <- shot.stats[i, "1"] + shot.stats[i, "0"]
}

# Find Feild Goal Percentage of each indivudual player in that match

shot.stats[, "FG.percentage"] <- NA 
for (i in 1:nrow(shot.stats)){
  shot.stats[i, "FG.percentage"] <- round(((shot.stats[i, "1"]/shot.stats[i, "FGA"]) * 100), digits = 2)
}
```

### Impact of Top Scorers

```{r, include=FALSE}
# Pick out 15 of the best players in that regular season and create a new subset. Analyse how shooting percentage of these players can influence the result of a match.

top.scorers.list <- c("mnta ellis", "lebron james", "james harden", "russell westbrook", "stephen curry", "anthony davis", "blake griffin", "lamarcus aldridge", "dwayne wade", "carmelo anthony", "eric bledsoe", "demarcus cousins", "kawhi leonard", "gordon hayward", "john wall") # 15 players picked out from all players
top.scorers <- shot.stats[shot.stats$player_name %in% top.scorers.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")] # create a subset for these players
top.scorers2 <- shot.stats[shot.stats$player_name %in% top.scorers.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")] # create a subset for these players

# Replace 1 and 0 with "W" and "L" respectively, 
top.scorers2[, "W"] <- as.numeric(top.scorers2[, "W"])
for (i in 1:nrow(top.scorers)) {
  if (top.scorers2[i, "W"] == 1) top.scorers2[i, "W"] <- "W"
  if (top.scorers2[i, "W"] == 0) top.scorers2[i, "W"] <- "L"
}
top.scorers2[, "W"] <- as.character(top.scorers2[, "W"])

# Correlation test
cor.test(top.scorers$W, top.scorers$FGA)
cor.test(top.scorers$W, top.scorers$FG.percentage)

# Linear regression
# summary(lm(FINAL_MARGIN ~ FGA + LOCATION, data = top.scorers)) # Final margin ~ FGA and location
# summary(lm(FINAL_MARGIN ~ FG.percentage + LOCATION, data = top.scorers)) # Final margin ~ FG% and location
# summary(lm(FINAL_MARGIN ~ FG.percentage + FGA + LOCATION, data = top.scorers)) 

# Logistic regression
model <- glm(W ~ FGA + FG.percentage, data = top.scorers)
summary(model)
anova(model)

```
###Results

####a. Field Goal Attempts (FGA)

There was no correlation found between the outcome of the matches in this season and the number of attempts of the players made. The Pearson’s correlation coefficient for the relationship between the variables W and FGA was r(832) < .01, p = .794, failing to reach the level of significance (p = .05). 

####b.  Field Goal Percentage (FG%)

There was no correlation found between the outcome of the matches in this seaon and the field goal percentage of the players. The Pearson’s correlation coefficient for the relationship between the variables W and FGA was r(832) < .01, p = .177, failing to reach the level of significance (p = .05). 

```{r, include=FALSE}
# Find out "special" players by t-test
# Russell Westbrook
t.test(top.scorers$FGA[top.scorers$player_name == "russell westbrook" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "russell westbrook" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "russell westbrook" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "russell westbrook" & top.scorers$W == "0"])
# Gordon Heyward
t.test(top.scorers$FGA[top.scorers$player_name == "gordon hayward" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "gordon hayward" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "gordon hayward" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "gordon hayward" & top.scorers$W == "0"])
# Kawhi Leonard
t.test(top.scorers$FGA[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "kawhi leonard" & top.scorers$W == "0"])
# Mnta Ellis
t.test(top.scorers$FGA[top.scorers$player_name == "mnta ellis" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "mnta ellis" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "mnta ellis" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "mnta ellis" & top.scorers$W == "0"])
# Lebron James
t.test(top.scorers$FGA[top.scorers$player_name == "lebron james" & top.scorers$W == "1"], top.scorers$FGA[top.scorers$player_name == "lebron james" & top.scorers$W == "0"])
t.test(top.scorers$FG.percentage[top.scorers$player_name == "lebron james" & top.scorers$W == "1"], top.scorers$FG.percentage[top.scorers$player_name == "lebron james" & top.scorers$W == "0"])

special.list <- c("gordon hayward", "russell westbrook", "kawhi leonard")
special <- shot.stats[shot.stats$player_name %in% special.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")]
special2 <- shot.stats[shot.stats$player_name %in% special.list, c("player_name", "W", "LOCATION", "FINAL_MARGIN", "FGA", "FG.percentage")]
special2[, "W"] <- as.numeric(special2[, "W"])
for (i in 1:nrow(special2)) {
  if (special2[i, "W"] == 1) special2[i, "W"] <- "W"
  if (special2[i, "W"] == 0) special2[i, "W"] <- "L"
}

ggplot(special2) + geom_boxplot(aes(x = player_name, y = FGA, colour = W))
ggplot(special2) + geom_boxplot(aes(x = player_name, y = FG.percentage, colour = W)) 

special.model <- glm(W ~ FGA + FG.percentage, data = special)
summary(special.model)
anova(special.model)

```
**Table 9**: Result for the logistic regression analysis for FGA and FG% of 15 players

   |   |Estimate | Std. Error | t value | Pr(>t)   
|-|-|-|- | -             
|(Intercept)  | 0.042259|   0.164816 |  0.256  |  0.798    
|FGA   |-0.002679|   0.006468 | -0.414  |  0.679    
|FG.percentage | 0.012329|   0.002736 |  4.506  |1.35e-05 ***

**Table 10**: Result for the anova for FGA and FG% for 15 players

   | |           Df| Deviance| Resid. Df| Resid. Dev
-|-|-|-|- 
|NULL        |     |              | 777   |  188.73
|FGA         |   1  | 0.0014   |    776  |   188.73
|FG.percentage | 1 |  7.4664   |    775  |   181.26

An ad hoc data analysis was used as 3 of the 15 players stood out in particular. To examine whether their data result in a better model, another logistic regression analysis was performed with the same dependent and independent variables for three special players: Russell Westbrook, Kawhi Leonard and Gordon Hayward.

```{r, echo=FALSE}
graph01 <- ggplot(special2) + geom_boxplot(aes(x = player_name, y = FGA, colour = W))
graph01 + labs(title = "Differences in FGA for games lost/won of the three special players") + xlab("Player name") + ylab("FGA")
```
Graph xx1: Differences in FGA for games lost/won of the three special players.
```{r, echo=FALSE}
graph02 <- ggplot(special2) + geom_boxplot(aes(x = player_name, y = FG.percentage, colour = W)) 
graph02 + labs(title = "Differences in FG% for games lost/won of the three special players") + xlab("Player name") + ylab("FG%")
```
Graph xx2: Differences in FG% for games lost/won of the three special players.

The box plots above shows the performances of the three special players in terms of FGA and FG% respectively.

**Table 11**: Result for the logistic regression analysis for FGA and FG% of the 3 special players

| | Estimate | Std. Error | t value | Pr(>t)   
|-|-|-|-| - 
|(Intercept)   | 0.042259 |  0.164816 |  0.256  |  0.798    
|FGA          | -0.002679 |  0.006468|  -0.414  |    0.679    
|FG.percentage|  0.012329|   0.002736|   4.506  |1.35e-05 ***

**Table 12**: Result for the anova for FGA and FG% for the 3 special players

| |         Df| Deviance| Resid. Df| Resid. Dev
|-|-|-|-| - 
|NULL         |   |         |       147|     36.669
|FGA          |  1|   0.0498|       146|     36.619
|FG.percentage|  1|   4.4978|       145|     32.121

###Discussion

From the correlation tests between the match results and players’ performances, it can be noticed that the increase in number of field goal attempts from top scorers is unlikely to make any impact on the results of the game. The p-values of both correlation tests are too high to reach the level of significance (p = .05).

From the logistic regression analysis for FGA and FG%, it was found that FGA did not have any impact on the result of the match. FG% is a significant predictor for the result of match. However, the anova showed that the residual deviances of these two factors were both quite large and thus further investigations must be done in order to improve this model.

There was no correlation found between field goal attempts of top scorers and outcome of the matches. A possible explanation is that it is easier for the opponent to focus on a certain player on defensive side and then the overall efficiency of the team will start to decrease. Thus, over-using the scoring ability of a leading player is not likely to be a good approach if the team wants to increase the likelyhood of winning a game. Meanwhile, the accuracy of these players has a stronger impact on the outcome of the game. This could be explained by that once a player is being efficient on the offensive side, that player can help the team not only by shooting but also by creating more opportunities for his teammates. 

Based on the results above, an additional analysis was done regarding the performance of three particular players: Russell Westbrook, Kawhi Leonard and Gordon Hayward. These three players were chosen because their teams are more likely to take the victory when they score more in single game according to Graph xx2 and t-test. 

For these three players, the p-values still did not reach the level of significance (p = .05) for FGA. However, all p-values are smaller than 0.05 when their FG%s were tested. Based on these findings, another logistic regression was done with these three players. It was shown that p < .05 and residual deviance from anova dropped by 4.498 which is about 12.3% when FG% was considered. In comparison, the deviance was above 180 when 15 players were analysed. For these three players, their teams are more likely to win by 1.2% when their FG% increase by 1.

Therefore, the analysis on these three players has shown that there is a difference between them and the others as they can contribute more to the win rates of their teams by their increasing shooting accuracy. There could be various reasons behind this observation, such as their team compositions and the roles of these players. Further research has to be done to in order to find out why the performances of these special players are more decisive on the outcome.

###Limitations
The data set only covers 904 of 1230 matches in the regular season. So there might be a chance that the highlight performances of certain players are missed out in the analysis. Meanwhile, it would be ideal if more aspects of data, such as rebounds and assists, could be analysed. 

##Defender Proximity Analysis  
###Closest Defender Distance vs Shot Accuracy
####Introduction  
This analysis focuses on whether there is a significant effect from closest defender distance to the shot outcome. The analysis is aimed to establish whether being away from the defender, i.e. having more time to prepare and execute a shot enables the shooter to score with a higher probability. Opposite effect will be when defender is close to the shooter it doesn't leave the shooter enough time to prepare and execute the shot properly.

The Null Hypothesis is that the distance to a closest defender does not have an impact on accuracy of shooting.  

###Methods  
The steps to calculate this measurement are as follows:  
  1. Assign shot result to determine whether the shot is scored (1) or missed (0)  
  2. Select and analyse subset of **all** closest defender distance values  
  3. Count the occurence fOr every distance  
  4. Calculate a number of uccessful shots for every distance point  
  5. Calculate accuracy ratio for every defender distance value  
  6. Plot and discuss the result
```{r, include=FALSE}
#Calculate accuracy against defender distance
#Group the defender distance level
distance_level <- as.data.frame(table(factor(df[, "CLOSE_DEF_DIST"])))
head(distance_level)

#Calculate how many times players scored in every defender distance
for (i in 1:nrow(distance_level)){
  distance_level[i, "SCORED"] <- sum(df[df[, "CLOSE_DEF_DIST"] == distance_level[i, "Var1"], "FGM"])
}

#Calculate shooting accuracy for each distance
distance_level$Accuracy <- round(distance_level$SCORED / distance_level$Freq, 4)

library(ggplot2)
library(scales)
ggplot(data = df) + geom_bar(aes(x = df[, "CLOSE_DEF_DIST"])) +
  scale_x_discrete("Closest Defender Distance", breaks = c (0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24), limits = 0:24)
  
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Plotting the result
library(ggplot2)
library(scales)
ggplot(data = distance_level, aes(x = distance_level$Var1, y = distance_level$Accuracy)) +
  geom_point(aes(x = distance_level$Var1, y = distance_level$Accuracy)) +
  scale_y_continuous(labels = percent, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0), limits = c(0, 1)) +
  scale_x_discrete("Closest Defender Distance", limits = 0:24) +  
  ylab("Shooting Accuracy (%)") +   ggtitle("Closest Defender Distance vs Shooting Accuracy")
```

###Plot Result
  The explanation from the plot above are as follows:   
  1. Defender distance range from 0 to 2 feet, the accuracy varied between 42% to 50%  
  2. Defender distance range from 2 to 4 feet, the accuracy rate for this distance range from 44% to 49%  
  3. Defender distance range from 4 to 6 feet, the accuracy rate for this distance range from 41% to 46%
  4. Defender distance range from 6 to 8 feet, the accuracy rate for this distance range from 37% to 42%
  5. Defender distance range from 8 to 10 feet, the accuracy rate for this distance range from 37% to 54%
  6. Defender distance more than 10 feet up until 16 feet, the accuracy varies greater than previous distance range, starting from 33% to 60%.  
  7. Distance greater than 16 feet, the data varies between 0% (no shots scored from that distance) to 100% (certain successfull shot from that distance)  

###Correlation Test
  Next analysis will be calculated from correlation test. If the analysis included **all** of the data points for every distance, the correlation result would be as follows:
  There was medium to strong positive correlation found between the defender distance and shooting accuracy. The Pearson’s correlation coefficient for the relationship between the variables Defender Distance and Accuracy was r(297) = .59, p < .05, as part of level of significance (p = .05).  
  
```{r, include=FALSE}
#change distance level to numeric type for correlation test function
distance_level$Var1 <- as.numeric(distance_level$Var1)
distance_level$Var1 <- distance_level$Var1 * 0.1 - 0.1 #to keep the distance point as it is

#populate data points from data frame
distanceZerotoAll <- c()
accuracyDist1 <- c()
for (i in 0:nrow(distance_level)){
  distanceZerotoAll <- c(distanceZerotoAll, distance_level[i, "Var1"])
  accuracyDist1 <- c(accuracyDist1, distance_level[i, "Accuracy"])
}

#combine data frame
dfZerotoAll <- data.frame(distanceZerotoAll, accuracyDist1)
```

```{r, include=FALSE}
#calculate correlation
cor.test(dfZerotoAll$distanceZerotoAll, dfZerotoAll$accuracyDist1)
```

###Correlation Test Result  
  The correlation test result produced slightly higher number of correlation between defender distance with shooting accuracy for all shot distance attempts (0.59). If the findings made only based on this number only, there would be obvious that further defender distance will **automatically** increase shooting accuracy. However, when analysing distance ranges the result was somewhat different. For example, for distance range between 0 (zero) to 8 feet, the correlation measurement will be as follows:  
  There was medium negative correlation found between the defender distance and shooting accuracy in this range. The Pearson’s correlation coefficient for the relationship between the variables Defender Distance and Accuracy was r(297) = -0.40, p < .05, as part of level of significance (p = .05).
```{r, include=FALSE}
#populate data from data frame
distanceZerotoEight <- c()
accuracyDist2 <- c()
for (i in 0:80){
  distanceZerotoEight <- c(distanceZerotoEight, distance_level[i, "Var1"])
  accuracyDist2 <- c(accuracyDist2, distance_level[i, "Accuracy"])
}

#combine data frame
dfZerotoEight <- data.frame(distanceZerotoEight, accuracyDist2)
```
  
```{r, include=FALSE}
#calculate correlation
cor.test(dfZerotoEight$distanceZerotoEight, dfZerotoEight$accuracyDist2)
```

  The correlation measurement between 0 (zero) to 8 feet would be negative (-0.40). This result was different with the previous calculation done for all data points (0.59).
  
###Discussion  
  The analysis demonstrated that the accuracy rate for every player was **affected** by the defender distance for certain ranges. For defender distance starting from 0 (zero) to 8 (eight) feet, the shooting accuracy had negative correlations. For the distance greater than 16 feet, the data varies between 0% (no shots scored from that distance) to 100% (certain successfull shot from that distance), which means that this part of the analysis should not be taken into account as the results were insignificant. It also shown from the dataset that only small attempt of shots were made from further defender distance. Therefore, it would affect the accuracy calculation result. However, from the correlation perspective, the result would be different if the analysis included all of the data points versus only short distance data points. This was arguably due to further defender distance did not mean the shooter distance from the basket was closer. Therefore, we **reject** the Null Hypothesis, since the defender distance affected shooting accuracy.  

###Future Research
  As the dataset did not hold many data points for more than 20 feet defender distance, the accuracy analysis for these distances are limited. The future analysis could be enhanced further by including data for additional seasons. 
  
###Shooting Distance vs Shot Accuracy
####Introduction  
This analysis focuses on whether there is any significant effect resulting from shooting distance from basket on the shot outcome. 

The NULL hypothesis is that the distance to the basket does not influence outcome of a shot.  

###Methods  
The steps to calculate this measurement are as follows:  
  1. Assign shot result to determine whether the shot is scored (1) or missed (0)  
  2. Select subsets of **all** shooting distances from the basket  
  3. Count the occurence fOr every distance to basket value  
  4. Allocate shot success rate to every distance from basket value  
  5. Plot and discuss the result
```{r, include=FALSE}
#Calculate accuracy against shooting distance
#Group the shooting distance level
shooting_distance_level <- as.data.frame(table(factor(df[, "SHOT_DIST"])))
head(shooting_distance_level)

#Calculate how many times players scored in every shooting distance
for (i in 1:nrow(shooting_distance_level)){
  shooting_distance_level[i, "SCORED"] <- sum(df[df[, "SHOT_DIST"] == shooting_distance_level[i, "Var1"], "FGM"])
}

#Calculate shooting accuracy for each distance
shooting_distance_level$Accuracy <- round(shooting_distance_level$SCORED / shooting_distance_level$Freq, 4)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Plotting the result
library(ggplot2)
library(scales)
ggplot(data = shooting_distance_level, aes(x = shooting_distance_level$Var1, y = shooting_distance_level$Accuracy)) + 
  geom_point(aes(x = shooting_distance_level$Var1, y = shooting_distance_level$Accuracy)) + 
  scale_y_continuous(labels = percent, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0), limits = c(0, 1)) +
  scale_x_discrete("Shooting Distance", limits = 0:43) + 
  geom_smooth() + 
  ylab("Shooting Accuracy (%)") + 
  ggtitle("Shooting Distance vs Shooting Accuracy")
```

###Plot Result
  The explanation from the plot above are as follows. The shooter distance ranges and accuracy:   
  1.  0 to 2 feet: the accuracy varied between **62%** to **68%**  
  2.  2 to 4 feet: the accuracy rate for this distance range from **61%** to **67%**  
  3.  4 to 6 feet: the accuracy rate for this distance range from **44%** to **58%**  
  4.  6 to 8 feet: the accuracy rate for this distance range from **38%** to **51%**  
  5.  8 to 10 feet: the accuracy rate for this distance range from **35%** to **42%**  
  6.  10 to 12 feet: the accuracy rate for this distance range from **34%** to **42%**  
  7.  12 to 14 feet: the accuracy rate for this distance range from **37%** to **47%**  
  8.  14 to 16 feet: the accuracy rate for this distance range from **33%** to **51%**  
  9.  16 to 18 feet: the accuracy rate for this distance range from **37%** to **48%**  
  10. 18 to 24 feet: the accuracy rate for this distance range from **33%** to **43%**  
  11. 24 to 28 feet: the accuracy rate for this distance range from **18%** to **38%**  
  12. more than 28 feet: the accuracy varies greater than previous distance range, starting from **0%** (no shots scored from that distance) to **50%**  

  Analysis has also produced a correlation test. If the analysis included **all** of the data points for every distance, the correlation result would be as follows:  
  There was strong negative correlation found between the shooting distance and shooting accuracy. The Pearson’s correlation coefficient for the relationship between the variables Shooting Distance and Shot Accuracy was r(446) = -0.87, p < .05, as part of level of significance (p = .05).
```{r, include=FALSE}
#change distance level to numeric type for correlation test function
shooting_distance_level$Var1 <- as.numeric(shooting_distance_level$Var1)
shooting_distance_level$Var1 <- shooting_distance_level$Var1 * 0.1 - 0.1 #to maintain distance data point as it is

#populate data for every shooting distance
shootingDistanceZerotoAll <- c()
shootingAccuracyDist1 <- c()
for (i in 0:nrow(shooting_distance_level)){
  shootingDistanceZerotoAll <- c(shootingDistanceZerotoAll, shooting_distance_level[i, "Var1"])
  shootingAccuracyDist1 <- c(shootingAccuracyDist1, shooting_distance_level[i, "Accuracy"])
}

dfShootingZerotoAll <- data.frame(shootingDistanceZerotoAll, shootingAccuracyDist1)
```

```{r, include=FALSE}
cor.test(dfShootingZerotoAll$shootingDistanceZerotoAll, dfShootingZerotoAll$shootingAccuracyDist1)
```

###Correlation Test Result  
  The correlation test result shown strong negative correlation between shooting distance and shooting accuracy (-0.87). This meant that for all data points, the further a shooter from the basket, the shooter's accuracy would decrease. However, if the correlation test taken for certain range distance based on the diagram, the correlation result would be different as follows:
  There was low positive correlation found between the shooting distance and shooting accuracy between range 10 to 20 feet. The Pearson’s correlation coefficient for the relationship between the variables Shooting Distance and Shot Accuracy was r(99) = .11, p > .05, fail to reach level of significance (p = .05).
```{r, include=FALSE}
#populate data for shooting distance in range 10 to 20 feet
shootingDistance10to20 <- c()
shootingAccuracyDist2 <- c()
for (i in 100:200){
  shootingDistance10to20 <- c(shootingDistance10to20, shooting_distance_level[i, "Var1"])
  shootingAccuracyDist2 <- c(shootingAccuracyDist2, shooting_distance_level[i, "Accuracy"])
}

dfShooting10to20 <- data.frame(shootingDistance10to20, shootingAccuracyDist2)
```
  
```{r, echo=FALSE}
cor.test(dfShooting10to20$shootingDistance10to20, dfShooting10to20$shootingAccuracyDist2)
```

  The second correlation test produced a small positive correlation between range 10 to 20 feet (0.11). This result was different with previous measurement (-0.87)  
  
###Discussion  
  Based on the diagram and correlation above, it could be concluded that although the shooting distance directly affects shooting accuracy, the relationship between these variables are not perfectly linear. This was shown in the diagram where there is a relatively **similar** shooting accuracy for shots taken from 10 feet to 20 feet, regardless the shooter's performance. The success rate for longer distances, it could be arguably inferred that the shooters tried to attempt a shot in closing game time (buzzer beater) when the shot clock or game clock nearly reach zero- hence a longer distances. Therefore, the analysis would reject the  Null Hypothesis.

###Future Research
 The dataset mostly returns 0% for shooting distance greater than 30 feet. Therefore the future research could be enriched with statistics from other seasons to see if these findings hold.  
  
***  
  
##Hot Hand Theory
###Introduction
  The specific analysis aims to show the effect of the 'hot hand theory' on NBA players. The analysis is based on the hypothesis that a shooter with a hot hand will have shots that are dependent of one another. If the shooter makes his first shot, the probability of making his next shot is higher.

###Methods
The steps to approximate this question are as follows:
  1. Calculate streaks achieved in all games and from all players
  2. Categorize streaks per player and game, focusing on the 3 players with the top 3 performances in terms of points
  3. Extract zeros and keep only streaks above 1
  4. Visualise streaks' length distribution - barplots
  5. Visualise streaks' length via boxplot
  6. Calculate the shooting percentage of the 3 players 
  7. Create a sample independent shooter 
  8. Compare distributions of sample and real player 

```{r, include=FALSE}

#From 'FGM' column: 1 represents a basket made and 0 represents a basket missed
#Defining the length of a shooting streak to be the number of consecutive baskets made until a miss occurs
#Creating a function that gives a vector with the number of total streaks(from all players and all games)
number_of_streaks <- function(x) {
  x <- c(0, x, 0)
  which_zero <- which(x == 0)
  streak <- diff(which_zero) - 1
  streak
}

number_of_streaks(df$FGM)

#Summary of total points
ptssum<- cast(df1, GAME_ID1+ player_id + player_name  ~ PTS); head(ptssum)
#Creating "total points per player, per game" column
ptssum$totalpts<- ptssum[,"2"]*2 + ptssum[,"3"]*3

pttsum2<-ptssum[order(ptssum$totalpts,decreasing=TRUE),]

#Setting a new data frame for the 3 players with best performances(higher points)
best_players_df <- head(pttsum2, 3)

#Creating a function that gives a vector of streaks for a specific player and game
player_and_game <- function(x, y) {
   player <- df[df[, 'player_id'] == x & df[,'GAME_ID1'] == y, 'FGM']
   number_of_streaks(as.vector(player))
}
#For the first player and game try:
#player_and_game('202681', '21400681')


#Creating a list that gives the streaks of each player and game (3 best performances)
streak_per_player <- list()
j <- 1
for(i in best_players_df$player_id) {
   streak_per_player[[j]] <- player_and_game(i, best_players_df[best_players_df[, 'player_id'] == i, 'GAME_ID1'])
   j <- j + 1
}
streak_per_player

#Removing zeros from streak_per_player in order to show only the streaks achieved
streak_per_player[[1]] <- streak_per_player[[1]][streak_per_player[[1]] != 0]
for(i in 1:length(streak_per_player)) {
  streak_per_player[[i]] <- streak_per_player[[i]][streak_per_player[[i]] != 0]
}
streak_per_player
```

###Barplots
```{r, include=FALSE}
#Creating a data frame for the strikes of each one of the 3 players (cannot create a data frame including all of them, because each list has different length)
player1_df <- data.frame('streaks' = streak_per_player[[1]])
player2_df <- data.frame('streaks' = streak_per_player[[2]])
player3_df <- data.frame('streaks' = streak_per_player[[3]])
```

```{r}
#Showing distribution for each player's streak lengths
gg1 <- ggplot(data = player1_df, aes(x = streaks)) + geom_bar(fill = 'brown') + labs(title = 'Kyrie Irnving')
gg2 <- ggplot(data = player2_df, aes(x = streaks)) + geom_bar(fill = 'red') + labs(title = 'Mo Williams')
gg3 <- ggplot(data = player3_df, aes(x = streaks)) + geom_bar(fill = 'blue') + labs(title = 'Klay Thompson')
grid.arrange(gg1, gg2, gg3, ncol = 3)
```

####Barplot result
  The distribution of the three players is unimodal and left skewed. There are shown some extremely long shooting streaks made (i.e. Klay Thompson with 13 shots in a row).  

###Boxplots

```{r}
#Create a boxplot for each player's streak lengths 
attach(mtcars)
par(mfrow=c(1, 3))
boxplot(player1_df$streaks, main = 'Kyrie Irnving')
boxplot(player2_df$streaks, main = 'Mo Williams')
boxplot(player3_df$streaks, main = 'Klay Thompson')
```

```{r, include=FALSE}
#Kyrie Irnving
summary(player1_df$streaks)
IQR(player1_df$streaks) 
```
#### Outcome for Kyrie Irnving:

  1. The typical length of a streak is 1 
  2. The Interquartile Range is 1 
  3. Streak length of 6 is unusually high compared to the rest of the distribution
  
```{r, include=FALSE}
#Mo Williams
summary(player2_df$streaks)
IQR(player2_df$streaks)
```

#### Outcome for Mo Williams

  1. The typical length of a streak is 1.5
  2. The Interquartile Range is 1
  3. Streak length of 4 is unusually high compared to the rest of the distribution

```{r, include=FALSE}
#Klay Thompson
summary(player3_df$streaks)
IQR(player3_df$streaks)
```

#### Outcome for Klay Thompson

  1. The typical length of a streak is 8 
  2. The Interquartile Range is 5
  3. There is a streak of length 13 

### Plots Result

  The distribution of all players is left skewed and all of them (especially Klay Thompson) have some long shooting streaks. In order to prove/disprove the hot hand theory,  the examination of the indipendence of the shots is required. If each shot that a player takes is independent of the next shot, then the player has the same probability of hitting each shot regardless of the previous shot. If each shot that a player takes is dependent of the next shot, then the probability of making the next shot is higher - hot hand. Sampling an independent shooter having the same shooting percentage with the real one and comparing his distribution with real player's distribution gives further insight in the specific aera. 

```{r, include=FALSE}
#Find the shooting percentage for each of the 3 players
j <- 1
shooting_percentage <- list()
for(i in best_players_df$player_id) {
  shooting_percentage[j] <- sum(df[df[, 'player_id'] == i, 'FGM']) / nrow(df[df[, 'player_id'] == i, ])
  j <- j + 1
}
shooting_percentage
```

###Kyrie Irving
```{r, include=FALSE}
###PLAYER 1 VS SAMPLE PLAYER###
#Simulation - creating a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter1 
set.seed(974)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[1]]), replace = TRUE, prob = c(shooting_percentage[[1]], 1 - shooting_percentage[[1]]))
simul_shooter


#Setting 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for (i in 1:length(simul_shooter)) {
   if (simul_shooter[i] == 'made') {
     simul_shooter[i] <- 1
   } else if (simul_shooter[i] == 'missed') {
     simul_shooter[i] <- 0
   }
}
simul_shooter

#Using previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Creating new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[1]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)
```

```{r}
#Comparing barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'red') + labs(title = 'Kyrie Irving')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result
  After running many times the sample, there are several times when the distributions of sample and real shooter are quite similar. As a consequence, it can be concluded that Mo Williams does not have a hot hand.

### Mo Williams
```{r, include=FALSE}
###PLAYER 2 VS SAMPLE PLAYER###
#Simulation - creating a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter2 
set.seed(572)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[2]]), replace = TRUE, 
                        prob = c(shooting_percentage[[2]], 1 - shooting_percentage[[2]]))
simul_shooter


#Setting 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for(i in 1:length(simul_shooter)) {
   if(simul_shooter[i] == 'made') simul_shooter[i] <- 1
   else if(simul_shooter[i] == 'missed') simul_shooter[i] <- 0
}
simul_shooter

#Using previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Creating new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[2]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)
```

```{r}
#Comparing barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'green') + labs(title = 'Mo Williams')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result

  After running many times the sample, there are several times when the distributions of sample and real shooter are quite similar. As a consequence, it can be concluded that Mo Williams does not have a hot hand.

###Klay Thompson
```{r, include=FALSE}
###PLAYER 3 VS SAMPLE PLAYER###
#Simulation - creating a vector of shots('made', 'missed') for a sample shooter, setting as probability the shooting percentage of the real shooter3 
set.seed(57)
shot_results <- c('made', 'missed')
simul_shooter <- sample(shot_results, size = length(streak_per_player[[3]]), replace = TRUE, 
                        prob = c(shooting_percentage[[3]], 1 - shooting_percentage[[3]]))
simul_shooter


#Setting 1 for baskets made and 0 for baskets missed
simul_shooter <- as.list(simul_shooter)
for(i in 1:length(simul_shooter)) {
   if(simul_shooter[i] == 'made') simul_shooter[i] <- 1
   else if(simul_shooter[i] == 'missed') simul_shooter[i] <- 0
}
simul_shooter

#Using previous function (number_of_streaks) to calculate the streaks made by the sample shooter 
streaks_of_simulshooter <- number_of_streaks(simul_shooter)

#Creating new data frames for the graphs 
simulshooter_df <- data.frame('streaks' = streaks_of_simulshooter)
realshooter_df <- data.frame('streaks' = streak_per_player[[3]])

#Comparisons of data between sample shooter and real shooters
summary(simulshooter_df$streaks)
summary(realshooter_df$streaks)
```

```{r}
#Comparing barplots of sample shooter and real shooter1
#If real shooter's streaks diverge significantly from an independent shooter's streaks(sample shooter's streaks), we can conclude tha the real shooter has a 'hot hand'. 
g1 <- ggplot(data = simulshooter_df, aes(x = streaks )) + geom_bar(fill = 'blue') + labs(title = 'sample shooter')
g2 <- ggplot(data = realshooter_df, aes(x = streaks)) + geom_bar(fill = 'brown') + labs(title = 'Klay Thompson')
grid.arrange(g1, g2, ncol = 2)
```

####Plot Result

  Klay Thompson is an exception making 13 shots in a row. There is no such distribution in the sample, so it could be assumed that he is likely to have a hot hand. Further statistical analysis - logistic regression - should be done in order to reach a more accurate conclusion.

###Discussion

  As the analysis shown, there are some extremely high shot streaks achieved from the players. Kyrie Irnving achieved six shots in a row, Mo Williams 4 shots in a row - twice, while Klay Thompson 13 shots in a row. However, to assume that a player has a hot hand, it is required to prove that his continuous shots are dependent of one another. As the vectors of streaks do not contain continuous variables, a linear regression cannot be used. Creating a sample independent shooter with same number of attempts and same shooting percentage as the real's one, is the closest approach to the specific question. In the first two cases, there are several times when the distribution of streaks of the sample independent player is similar to the real shooter's distribution. As the sample shooter's distribution visualises independent shots, it can be concluded that Kyrie Irnving's and Mo Williams' continuous shots are independent of one another and as a result they have not a hot hand. On the other hand, Klay Thompson is likely to have a hot hand, as his shots length distribution diverges significantly from sample's distribution.   
 
###Limitations

  Since the dataset is referred to only one season, the size of the vectors of streaks for each player is very small, a fact that can lead to misleading results. Moreover, streaks do not constitute continuous variables and as a result they cannot be used in a linear regression.
  
###Future research

  Since the dataset is reffered to only one season and the analysis is not able to eliminate the hot hand theory, it would be an interesting topic to be investigated in future seasons. 
 
 

```{r, include=FALSE}
#Regression Analysis

df1$GAME_CLOCK <- as.numeric(df1$GAME_CLOCK)

df1$AWAY_TEAM <- as.character(df1$AWAY_TEAM)

linreg_fgm <- lm(FGM ~ LOCATION + W + FINAL_MARGIN + SHOT_NUMBER + PERIOD + GAME_CLOCK + SHOT_CLOCK+ DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSEST_DEFENDER_PLAYER_ID + CLOSE_DEF_DIST + player_id + WINNER, df1)

summary(linreg_fgm)

linreg_fgm2 <- lm(FGM ~ FINAL_MARGIN + SHOT_NUMBER + PERIOD + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + SHOT_DIST + PTS_TYPE + CLOSE_DEF_DIST + player_id, df1 )


summary(linreg_fgm2)

```

***
#Conclusion

This report has demonstrated results of mathematical and statistical analysis of the dataset containing information of shots from NBA season 2014-2015. The report specifically focused on number of research areas covering teams and players performance. The report described steps taken to produce the results, discussed and evaluated the produced results and suggested potential areas for future research.  


***
#References

  Ahart (1973). In Kendall, P. and Hollon, S. (1979). Cognitive-behavioral interventions. New York: Academic Press.
  Economist: As sweet as ever (2015) Available at: http://www.economist.com/blogs/gametheory/2015/06/home-advantage-basketball (Accessed: 16 October 2016).
  Erculj, F. and Supej, M. (2009). Impact of Fatigue on the Position of the Release Arm and Shoulder Girdle over a Longer Shooting Distance for an Elite Basketball Player. Journal of Strength and Conditioning Research, 23(3), pp.1029-1036.
  Mascret, N., Ibáñez-Gijón, J., Bréjard, V., Buekers, M., Casanova, R., Marqueste, T., Montagne, G., Rao, G., Roux, Y. and Cury, F. (2016). The Influence of the ‘Trier Social Stress Test’ on Free Throw Performance in Basketball: An Interdisciplinary Study. PLOS ONE, 11(6), p.e0157215.
<<<<<<< HEAD

ECONOMIST. As sweet as ever (2015) Available at: http://www.economist.com/blogs/gametheory/2015/06/home-advantage-basketball (Accessed: 16 October 2016).
=======
  
>>>>>>> 1824e38efa8c0d5a6ec4a49d8509279897c8a360
